{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcab6b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4039eb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>RF</th>\n",
       "      <th>T max</th>\n",
       "      <th>T min</th>\n",
       "      <th>Avg_tem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.1</td>\n",
       "      <td>25.8</td>\n",
       "      <td>28.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.3</td>\n",
       "      <td>27.5</td>\n",
       "      <td>29.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.6</td>\n",
       "      <td>31.3</td>\n",
       "      <td>27.3</td>\n",
       "      <td>29.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2013</td>\n",
       "      <td>5.8</td>\n",
       "      <td>30.7</td>\n",
       "      <td>25.7</td>\n",
       "      <td>28.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.3</td>\n",
       "      <td>30.8</td>\n",
       "      <td>24.4</td>\n",
       "      <td>27.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Date  Month  Year   RF  T max   T min  Avg_tem\n",
       "0     1     10  2013  0.0    31.1   25.8    28.45\n",
       "1     2     10  2013  0.0    31.3   27.5    29.40\n",
       "2     3     10  2013  1.6    31.3   27.3    29.30\n",
       "3     4     10  2013  5.8    30.7   25.7    28.20\n",
       "4     5     10  2013  0.3    30.8   24.4    27.60"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('NewSl.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44eca4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg_tem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Avg_tem\n",
       "0    28.45\n",
       "1    29.40\n",
       "2    29.30\n",
       "3    28.20\n",
       "4    27.60"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_mod1 = dataset[['Avg_tem']]\n",
    "dataset_mod1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ce13785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      28.45\n",
       "1      29.40\n",
       "2      29.30\n",
       "3      28.20\n",
       "4      27.60\n",
       "       ...  \n",
       "360    27.40\n",
       "361    27.50\n",
       "362    27.90\n",
       "363    28.05\n",
       "364    27.35\n",
       "Name: Avg_tem, Length: 365, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = dataset_mod1.iloc[0:365,0]\n",
    "\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "353c9592",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce3c5812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28.45],\n",
       "       [29.4 ],\n",
       "       [29.3 ],\n",
       "       [28.2 ],\n",
       "       [27.6 ],\n",
       "       [28.05],\n",
       "       [27.75],\n",
       "       [27.65],\n",
       "       [29.1 ],\n",
       "       [28.05],\n",
       "       [28.4 ],\n",
       "       [27.95],\n",
       "       [28.25],\n",
       "       [28.1 ],\n",
       "       [28.25],\n",
       "       [28.85],\n",
       "       [27.7 ],\n",
       "       [27.25],\n",
       "       [25.7 ],\n",
       "       [26.7 ],\n",
       "       [28.35],\n",
       "       [27.7 ],\n",
       "       [28.9 ],\n",
       "       [28.2 ],\n",
       "       [27.75],\n",
       "       [27.55],\n",
       "       [27.75],\n",
       "       [28.3 ],\n",
       "       [27.75],\n",
       "       [27.55],\n",
       "       [27.3 ],\n",
       "       [27.3 ],\n",
       "       [27.3 ],\n",
       "       [27.  ],\n",
       "       [27.8 ],\n",
       "       [27.7 ],\n",
       "       [27.8 ],\n",
       "       [27.55],\n",
       "       [27.45],\n",
       "       [28.1 ],\n",
       "       [27.15],\n",
       "       [28.25],\n",
       "       [28.35],\n",
       "       [27.  ],\n",
       "       [28.15],\n",
       "       [27.85],\n",
       "       [27.5 ],\n",
       "       [28.35],\n",
       "       [27.9 ],\n",
       "       [27.4 ],\n",
       "       [27.25],\n",
       "       [27.4 ],\n",
       "       [28.05],\n",
       "       [27.65],\n",
       "       [26.75],\n",
       "       [27.4 ],\n",
       "       [27.45],\n",
       "       [27.35],\n",
       "       [27.  ],\n",
       "       [27.75],\n",
       "       [28.5 ],\n",
       "       [26.75],\n",
       "       [27.45],\n",
       "       [27.75],\n",
       "       [28.  ],\n",
       "       [27.1 ],\n",
       "       [27.05],\n",
       "       [27.25],\n",
       "       [27.05],\n",
       "       [27.5 ],\n",
       "       [26.8 ],\n",
       "       [27.4 ],\n",
       "       [27.55],\n",
       "       [26.85],\n",
       "       [27.3 ],\n",
       "       [27.15],\n",
       "       [27.35],\n",
       "       [26.45],\n",
       "       [27.85],\n",
       "       [27.75],\n",
       "       [27.6 ],\n",
       "       [27.85],\n",
       "       [28.2 ],\n",
       "       [27.85],\n",
       "       [27.6 ],\n",
       "       [27.8 ],\n",
       "       [27.35],\n",
       "       [27.3 ],\n",
       "       [27.95],\n",
       "       [27.5 ],\n",
       "       [27.25],\n",
       "       [28.1 ],\n",
       "       [28.65],\n",
       "       [27.65],\n",
       "       [27.7 ],\n",
       "       [27.15],\n",
       "       [26.05],\n",
       "       [26.7 ],\n",
       "       [26.85],\n",
       "       [27.4 ],\n",
       "       [28.05],\n",
       "       [27.2 ],\n",
       "       [26.85],\n",
       "       [27.15],\n",
       "       [27.6 ],\n",
       "       [27.05],\n",
       "       [27.5 ],\n",
       "       [26.8 ],\n",
       "       [27.95],\n",
       "       [26.2 ],\n",
       "       [27.8 ],\n",
       "       [26.95],\n",
       "       [28.8 ],\n",
       "       [27.55],\n",
       "       [27.75],\n",
       "       [27.45],\n",
       "       [27.9 ],\n",
       "       [27.15],\n",
       "       [27.65],\n",
       "       [28.  ],\n",
       "       [28.25],\n",
       "       [28.65],\n",
       "       [28.4 ],\n",
       "       [29.65],\n",
       "       [29.8 ],\n",
       "       [29.05],\n",
       "       [27.4 ],\n",
       "       [27.1 ],\n",
       "       [26.9 ],\n",
       "       [28.2 ],\n",
       "       [26.65],\n",
       "       [26.2 ],\n",
       "       [25.35],\n",
       "       [25.25],\n",
       "       [26.55],\n",
       "       [26.15],\n",
       "       [27.45],\n",
       "       [26.85],\n",
       "       [27.6 ],\n",
       "       [27.55],\n",
       "       [28.1 ],\n",
       "       [28.85],\n",
       "       [28.35],\n",
       "       [28.9 ],\n",
       "       [27.6 ],\n",
       "       [27.95],\n",
       "       [27.55],\n",
       "       [28.55],\n",
       "       [28.15],\n",
       "       [28.05],\n",
       "       [27.7 ],\n",
       "       [28.1 ],\n",
       "       [28.45],\n",
       "       [28.75],\n",
       "       [28.8 ],\n",
       "       [29.4 ],\n",
       "       [28.  ],\n",
       "       [28.1 ],\n",
       "       [27.7 ],\n",
       "       [29.25],\n",
       "       [28.55],\n",
       "       [29.75],\n",
       "       [28.45],\n",
       "       [28.45],\n",
       "       [27.8 ],\n",
       "       [27.8 ],\n",
       "       [28.4 ],\n",
       "       [28.75],\n",
       "       [29.35],\n",
       "       [27.2 ],\n",
       "       [28.65],\n",
       "       [28.8 ],\n",
       "       [28.15],\n",
       "       [29.15],\n",
       "       [28.7 ],\n",
       "       [28.65],\n",
       "       [29.05],\n",
       "       [29.3 ],\n",
       "       [28.25],\n",
       "       [28.65],\n",
       "       [28.9 ],\n",
       "       [28.65],\n",
       "       [28.65],\n",
       "       [30.15],\n",
       "       [29.5 ],\n",
       "       [28.45],\n",
       "       [28.95],\n",
       "       [28.2 ],\n",
       "       [28.85],\n",
       "       [29.05],\n",
       "       [28.25],\n",
       "       [28.8 ],\n",
       "       [28.85],\n",
       "       [28.6 ],\n",
       "       [29.15],\n",
       "       [28.6 ],\n",
       "       [27.45],\n",
       "       [29.3 ],\n",
       "       [28.95],\n",
       "       [29.  ],\n",
       "       [28.55],\n",
       "       [28.75],\n",
       "       [29.55],\n",
       "       [29.05],\n",
       "       [27.85],\n",
       "       [28.25],\n",
       "       [28.4 ],\n",
       "       [29.45],\n",
       "       [29.4 ],\n",
       "       [28.85],\n",
       "       [27.8 ],\n",
       "       [27.75],\n",
       "       [27.7 ],\n",
       "       [29.05],\n",
       "       [27.2 ],\n",
       "       [27.5 ],\n",
       "       [28.05],\n",
       "       [27.4 ],\n",
       "       [27.85],\n",
       "       [27.75],\n",
       "       [28.5 ],\n",
       "       [29.1 ],\n",
       "       [29.05],\n",
       "       [29.15],\n",
       "       [29.55],\n",
       "       [30.3 ],\n",
       "       [30.4 ],\n",
       "       [30.75],\n",
       "       [29.95],\n",
       "       [29.95],\n",
       "       [29.3 ],\n",
       "       [29.4 ],\n",
       "       [28.8 ],\n",
       "       [28.95],\n",
       "       [30.25],\n",
       "       [30.6 ],\n",
       "       [29.15],\n",
       "       [29.35],\n",
       "       [30.  ],\n",
       "       [29.55],\n",
       "       [28.25],\n",
       "       [29.2 ],\n",
       "       [29.9 ],\n",
       "       [29.25],\n",
       "       [26.15],\n",
       "       [26.15],\n",
       "       [28.  ],\n",
       "       [29.4 ],\n",
       "       [29.8 ],\n",
       "       [29.95],\n",
       "       [29.7 ],\n",
       "       [28.95],\n",
       "       [29.6 ],\n",
       "       [28.1 ],\n",
       "       [28.4 ],\n",
       "       [27.35],\n",
       "       [29.6 ],\n",
       "       [29.4 ],\n",
       "       [29.55],\n",
       "       [29.3 ],\n",
       "       [29.6 ],\n",
       "       [29.55],\n",
       "       [29.55],\n",
       "       [30.  ],\n",
       "       [29.9 ],\n",
       "       [29.75],\n",
       "       [29.85],\n",
       "       [29.85],\n",
       "       [29.6 ],\n",
       "       [29.7 ],\n",
       "       [28.75],\n",
       "       [29.  ],\n",
       "       [27.4 ],\n",
       "       [27.05],\n",
       "       [27.85],\n",
       "       [29.35],\n",
       "       [29.2 ],\n",
       "       [28.9 ],\n",
       "       [28.8 ],\n",
       "       [28.95],\n",
       "       [29.1 ],\n",
       "       [29.  ],\n",
       "       [28.6 ],\n",
       "       [27.7 ],\n",
       "       [29.15],\n",
       "       [29.3 ],\n",
       "       [28.85],\n",
       "       [28.75],\n",
       "       [28.  ],\n",
       "       [29.2 ],\n",
       "       [29.25],\n",
       "       [29.6 ],\n",
       "       [29.  ],\n",
       "       [29.25],\n",
       "       [29.5 ],\n",
       "       [28.55],\n",
       "       [29.4 ],\n",
       "       [29.45],\n",
       "       [29.4 ],\n",
       "       [29.05],\n",
       "       [28.  ],\n",
       "       [27.55],\n",
       "       [29.15],\n",
       "       [29.15],\n",
       "       [29.  ],\n",
       "       [27.1 ],\n",
       "       [27.7 ],\n",
       "       [27.65],\n",
       "       [28.55],\n",
       "       [27.95],\n",
       "       [28.65],\n",
       "       [28.85],\n",
       "       [27.8 ],\n",
       "       [28.4 ],\n",
       "       [26.95],\n",
       "       [26.8 ],\n",
       "       [27.25],\n",
       "       [28.5 ],\n",
       "       [28.65],\n",
       "       [28.65],\n",
       "       [26.85],\n",
       "       [27.1 ],\n",
       "       [27.35],\n",
       "       [27.4 ],\n",
       "       [26.9 ],\n",
       "       [25.8 ],\n",
       "       [26.95],\n",
       "       [27.4 ],\n",
       "       [27.95],\n",
       "       [27.9 ],\n",
       "       [28.65],\n",
       "       [29.15],\n",
       "       [29.05],\n",
       "       [29.05],\n",
       "       [28.  ],\n",
       "       [29.15],\n",
       "       [27.15],\n",
       "       [26.7 ],\n",
       "       [26.4 ],\n",
       "       [27.25],\n",
       "       [28.15],\n",
       "       [27.75],\n",
       "       [27.45],\n",
       "       [27.  ],\n",
       "       [27.45],\n",
       "       [28.  ],\n",
       "       [28.75],\n",
       "       [29.2 ],\n",
       "       [28.4 ],\n",
       "       [27.75],\n",
       "       [28.55],\n",
       "       [28.25],\n",
       "       [28.65],\n",
       "       [28.25],\n",
       "       [28.95],\n",
       "       [28.25],\n",
       "       [28.3 ],\n",
       "       [28.7 ],\n",
       "       [28.25],\n",
       "       [27.9 ],\n",
       "       [27.4 ],\n",
       "       [27.5 ],\n",
       "       [27.9 ],\n",
       "       [28.05],\n",
       "       [27.35]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = training_set.values.reshape(len(training_set), 1)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd8059b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58181818],\n",
       "       [0.75454545],\n",
       "       [0.73636364],\n",
       "       [0.53636364],\n",
       "       [0.42727273],\n",
       "       [0.50909091],\n",
       "       [0.45454545],\n",
       "       [0.43636364],\n",
       "       [0.7       ],\n",
       "       [0.50909091],\n",
       "       [0.57272727],\n",
       "       [0.49090909],\n",
       "       [0.54545455],\n",
       "       [0.51818182],\n",
       "       [0.54545455],\n",
       "       [0.65454545],\n",
       "       [0.44545455],\n",
       "       [0.36363636],\n",
       "       [0.08181818],\n",
       "       [0.26363636],\n",
       "       [0.56363636],\n",
       "       [0.44545455],\n",
       "       [0.66363636],\n",
       "       [0.53636364],\n",
       "       [0.45454545],\n",
       "       [0.41818182],\n",
       "       [0.45454545],\n",
       "       [0.55454545],\n",
       "       [0.45454545],\n",
       "       [0.41818182],\n",
       "       [0.37272727],\n",
       "       [0.37272727],\n",
       "       [0.37272727],\n",
       "       [0.31818182],\n",
       "       [0.46363636],\n",
       "       [0.44545455],\n",
       "       [0.46363636],\n",
       "       [0.41818182],\n",
       "       [0.4       ],\n",
       "       [0.51818182],\n",
       "       [0.34545455],\n",
       "       [0.54545455],\n",
       "       [0.56363636],\n",
       "       [0.31818182],\n",
       "       [0.52727273],\n",
       "       [0.47272727],\n",
       "       [0.40909091],\n",
       "       [0.56363636],\n",
       "       [0.48181818],\n",
       "       [0.39090909],\n",
       "       [0.36363636],\n",
       "       [0.39090909],\n",
       "       [0.50909091],\n",
       "       [0.43636364],\n",
       "       [0.27272727],\n",
       "       [0.39090909],\n",
       "       [0.4       ],\n",
       "       [0.38181818],\n",
       "       [0.31818182],\n",
       "       [0.45454545],\n",
       "       [0.59090909],\n",
       "       [0.27272727],\n",
       "       [0.4       ],\n",
       "       [0.45454545],\n",
       "       [0.5       ],\n",
       "       [0.33636364],\n",
       "       [0.32727273],\n",
       "       [0.36363636],\n",
       "       [0.32727273],\n",
       "       [0.40909091],\n",
       "       [0.28181818],\n",
       "       [0.39090909],\n",
       "       [0.41818182],\n",
       "       [0.29090909],\n",
       "       [0.37272727],\n",
       "       [0.34545455],\n",
       "       [0.38181818],\n",
       "       [0.21818182],\n",
       "       [0.47272727],\n",
       "       [0.45454545],\n",
       "       [0.42727273],\n",
       "       [0.47272727],\n",
       "       [0.53636364],\n",
       "       [0.47272727],\n",
       "       [0.42727273],\n",
       "       [0.46363636],\n",
       "       [0.38181818],\n",
       "       [0.37272727],\n",
       "       [0.49090909],\n",
       "       [0.40909091],\n",
       "       [0.36363636],\n",
       "       [0.51818182],\n",
       "       [0.61818182],\n",
       "       [0.43636364],\n",
       "       [0.44545455],\n",
       "       [0.34545455],\n",
       "       [0.14545455],\n",
       "       [0.26363636],\n",
       "       [0.29090909],\n",
       "       [0.39090909],\n",
       "       [0.50909091],\n",
       "       [0.35454545],\n",
       "       [0.29090909],\n",
       "       [0.34545455],\n",
       "       [0.42727273],\n",
       "       [0.32727273],\n",
       "       [0.40909091],\n",
       "       [0.28181818],\n",
       "       [0.49090909],\n",
       "       [0.17272727],\n",
       "       [0.46363636],\n",
       "       [0.30909091],\n",
       "       [0.64545455],\n",
       "       [0.41818182],\n",
       "       [0.45454545],\n",
       "       [0.4       ],\n",
       "       [0.48181818],\n",
       "       [0.34545455],\n",
       "       [0.43636364],\n",
       "       [0.5       ],\n",
       "       [0.54545455],\n",
       "       [0.61818182],\n",
       "       [0.57272727],\n",
       "       [0.8       ],\n",
       "       [0.82727273],\n",
       "       [0.69090909],\n",
       "       [0.39090909],\n",
       "       [0.33636364],\n",
       "       [0.3       ],\n",
       "       [0.53636364],\n",
       "       [0.25454545],\n",
       "       [0.17272727],\n",
       "       [0.01818182],\n",
       "       [0.        ],\n",
       "       [0.23636364],\n",
       "       [0.16363636],\n",
       "       [0.4       ],\n",
       "       [0.29090909],\n",
       "       [0.42727273],\n",
       "       [0.41818182],\n",
       "       [0.51818182],\n",
       "       [0.65454545],\n",
       "       [0.56363636],\n",
       "       [0.66363636],\n",
       "       [0.42727273],\n",
       "       [0.49090909],\n",
       "       [0.41818182],\n",
       "       [0.6       ],\n",
       "       [0.52727273],\n",
       "       [0.50909091],\n",
       "       [0.44545455],\n",
       "       [0.51818182],\n",
       "       [0.58181818],\n",
       "       [0.63636364],\n",
       "       [0.64545455],\n",
       "       [0.75454545],\n",
       "       [0.5       ],\n",
       "       [0.51818182],\n",
       "       [0.44545455],\n",
       "       [0.72727273],\n",
       "       [0.6       ],\n",
       "       [0.81818182],\n",
       "       [0.58181818],\n",
       "       [0.58181818],\n",
       "       [0.46363636],\n",
       "       [0.46363636],\n",
       "       [0.57272727],\n",
       "       [0.63636364],\n",
       "       [0.74545455],\n",
       "       [0.35454545],\n",
       "       [0.61818182],\n",
       "       [0.64545455],\n",
       "       [0.52727273],\n",
       "       [0.70909091],\n",
       "       [0.62727273],\n",
       "       [0.61818182],\n",
       "       [0.69090909],\n",
       "       [0.73636364],\n",
       "       [0.54545455],\n",
       "       [0.61818182],\n",
       "       [0.66363636],\n",
       "       [0.61818182],\n",
       "       [0.61818182],\n",
       "       [0.89090909],\n",
       "       [0.77272727],\n",
       "       [0.58181818],\n",
       "       [0.67272727],\n",
       "       [0.53636364],\n",
       "       [0.65454545],\n",
       "       [0.69090909],\n",
       "       [0.54545455],\n",
       "       [0.64545455],\n",
       "       [0.65454545],\n",
       "       [0.60909091],\n",
       "       [0.70909091],\n",
       "       [0.60909091],\n",
       "       [0.4       ],\n",
       "       [0.73636364],\n",
       "       [0.67272727],\n",
       "       [0.68181818],\n",
       "       [0.6       ],\n",
       "       [0.63636364],\n",
       "       [0.78181818],\n",
       "       [0.69090909],\n",
       "       [0.47272727],\n",
       "       [0.54545455],\n",
       "       [0.57272727],\n",
       "       [0.76363636],\n",
       "       [0.75454545],\n",
       "       [0.65454545],\n",
       "       [0.46363636],\n",
       "       [0.45454545],\n",
       "       [0.44545455],\n",
       "       [0.69090909],\n",
       "       [0.35454545],\n",
       "       [0.40909091],\n",
       "       [0.50909091],\n",
       "       [0.39090909],\n",
       "       [0.47272727],\n",
       "       [0.45454545],\n",
       "       [0.59090909],\n",
       "       [0.7       ],\n",
       "       [0.69090909],\n",
       "       [0.70909091],\n",
       "       [0.78181818],\n",
       "       [0.91818182],\n",
       "       [0.93636364],\n",
       "       [1.        ],\n",
       "       [0.85454545],\n",
       "       [0.85454545],\n",
       "       [0.73636364],\n",
       "       [0.75454545],\n",
       "       [0.64545455],\n",
       "       [0.67272727],\n",
       "       [0.90909091],\n",
       "       [0.97272727],\n",
       "       [0.70909091],\n",
       "       [0.74545455],\n",
       "       [0.86363636],\n",
       "       [0.78181818],\n",
       "       [0.54545455],\n",
       "       [0.71818182],\n",
       "       [0.84545455],\n",
       "       [0.72727273],\n",
       "       [0.16363636],\n",
       "       [0.16363636],\n",
       "       [0.5       ],\n",
       "       [0.75454545],\n",
       "       [0.82727273],\n",
       "       [0.85454545],\n",
       "       [0.80909091],\n",
       "       [0.67272727],\n",
       "       [0.79090909],\n",
       "       [0.51818182],\n",
       "       [0.57272727],\n",
       "       [0.38181818],\n",
       "       [0.79090909],\n",
       "       [0.75454545],\n",
       "       [0.78181818],\n",
       "       [0.73636364],\n",
       "       [0.79090909],\n",
       "       [0.78181818],\n",
       "       [0.78181818],\n",
       "       [0.86363636],\n",
       "       [0.84545455],\n",
       "       [0.81818182],\n",
       "       [0.83636364],\n",
       "       [0.83636364],\n",
       "       [0.79090909],\n",
       "       [0.80909091],\n",
       "       [0.63636364],\n",
       "       [0.68181818],\n",
       "       [0.39090909],\n",
       "       [0.32727273],\n",
       "       [0.47272727],\n",
       "       [0.74545455],\n",
       "       [0.71818182],\n",
       "       [0.66363636],\n",
       "       [0.64545455],\n",
       "       [0.67272727],\n",
       "       [0.7       ],\n",
       "       [0.68181818],\n",
       "       [0.60909091],\n",
       "       [0.44545455],\n",
       "       [0.70909091],\n",
       "       [0.73636364],\n",
       "       [0.65454545],\n",
       "       [0.63636364],\n",
       "       [0.5       ],\n",
       "       [0.71818182],\n",
       "       [0.72727273],\n",
       "       [0.79090909],\n",
       "       [0.68181818],\n",
       "       [0.72727273],\n",
       "       [0.77272727],\n",
       "       [0.6       ],\n",
       "       [0.75454545],\n",
       "       [0.76363636],\n",
       "       [0.75454545],\n",
       "       [0.69090909],\n",
       "       [0.5       ],\n",
       "       [0.41818182],\n",
       "       [0.70909091],\n",
       "       [0.70909091],\n",
       "       [0.68181818],\n",
       "       [0.33636364],\n",
       "       [0.44545455],\n",
       "       [0.43636364],\n",
       "       [0.6       ],\n",
       "       [0.49090909],\n",
       "       [0.61818182],\n",
       "       [0.65454545],\n",
       "       [0.46363636],\n",
       "       [0.57272727],\n",
       "       [0.30909091],\n",
       "       [0.28181818],\n",
       "       [0.36363636],\n",
       "       [0.59090909],\n",
       "       [0.61818182],\n",
       "       [0.61818182],\n",
       "       [0.29090909],\n",
       "       [0.33636364],\n",
       "       [0.38181818],\n",
       "       [0.39090909],\n",
       "       [0.3       ],\n",
       "       [0.1       ],\n",
       "       [0.30909091],\n",
       "       [0.39090909],\n",
       "       [0.49090909],\n",
       "       [0.48181818],\n",
       "       [0.61818182],\n",
       "       [0.70909091],\n",
       "       [0.69090909],\n",
       "       [0.69090909],\n",
       "       [0.5       ],\n",
       "       [0.70909091],\n",
       "       [0.34545455],\n",
       "       [0.26363636],\n",
       "       [0.20909091],\n",
       "       [0.36363636],\n",
       "       [0.52727273],\n",
       "       [0.45454545],\n",
       "       [0.4       ],\n",
       "       [0.31818182],\n",
       "       [0.4       ],\n",
       "       [0.5       ],\n",
       "       [0.63636364],\n",
       "       [0.71818182],\n",
       "       [0.57272727],\n",
       "       [0.45454545],\n",
       "       [0.6       ],\n",
       "       [0.54545455],\n",
       "       [0.61818182],\n",
       "       [0.54545455],\n",
       "       [0.67272727],\n",
       "       [0.54545455],\n",
       "       [0.55454545],\n",
       "       [0.62727273],\n",
       "       [0.54545455],\n",
       "       [0.48181818],\n",
       "       [0.39090909],\n",
       "       [0.40909091],\n",
       "       [0.48181818],\n",
       "       [0.50909091],\n",
       "       [0.38181818]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_scaled = sc.fit_transform(training_set)\n",
    "training_set_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53c1d15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "n_future = 4 # next 4 days temperature forecast\n",
    "n_past = 30 # Past 30 days \n",
    "for i in range(0,len(training_set_scaled)-n_past-n_future+1):\n",
    "    x_train.append(training_set_scaled[i : i + n_past , 0])     \n",
    "    y_train.append(training_set_scaled[i + n_past : i + n_past + n_future , 0 ])\n",
    "x_train , y_train = np.array(x_train), np.array(y_train)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0] , x_train.shape[1], 1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "811edc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Sevindu\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61a764f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM,Dense ,Dropout\n",
    "# Fitting RNN to training set using Keras Callbacks. Read Keras callbacks docs for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b26a1f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Sevindu\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Sevindu\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:From C:\\Users\\Sevindu\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Sevindu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "9/9 [==============================] - 8s 196ms/step - loss: 0.2198 - acc: 0.2264 - val_loss: 0.0342 - val_acc: 0.2388\n",
      "Epoch 2/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0640 - acc: 0.2340 - val_loss: 0.0368 - val_acc: 0.2985\n",
      "Epoch 3/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0496 - acc: 0.2981 - val_loss: 0.0268 - val_acc: 0.2388\n",
      "Epoch 4/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0440 - acc: 0.2340 - val_loss: 0.0231 - val_acc: 0.2388\n",
      "Epoch 5/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0432 - acc: 0.2302 - val_loss: 0.0237 - val_acc: 0.2985\n",
      "Epoch 6/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0386 - acc: 0.2717 - val_loss: 0.0246 - val_acc: 0.2388\n",
      "Epoch 7/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0376 - acc: 0.3132 - val_loss: 0.0237 - val_acc: 0.2388\n",
      "Epoch 8/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0354 - acc: 0.2717 - val_loss: 0.0242 - val_acc: 0.2388\n",
      "Epoch 9/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0375 - acc: 0.2528 - val_loss: 0.0241 - val_acc: 0.2836\n",
      "Epoch 10/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0369 - acc: 0.2491 - val_loss: 0.0279 - val_acc: 0.2836\n",
      "Epoch 11/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0358 - acc: 0.2604 - val_loss: 0.0244 - val_acc: 0.2836\n",
      "Epoch 12/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0340 - acc: 0.2415 - val_loss: 0.0256 - val_acc: 0.2985\n",
      "Epoch 13/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0338 - acc: 0.3057 - val_loss: 0.0279 - val_acc: 0.2388\n",
      "Epoch 14/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0312 - acc: 0.2679 - val_loss: 0.0338 - val_acc: 0.2388\n",
      "Epoch 15/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0375 - acc: 0.2377 - val_loss: 0.0241 - val_acc: 0.2985\n",
      "Epoch 16/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0338 - acc: 0.2302 - val_loss: 0.0265 - val_acc: 0.2687\n",
      "Epoch 17/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0322 - acc: 0.2906 - val_loss: 0.0287 - val_acc: 0.2388\n",
      "Epoch 18/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0352 - acc: 0.2302 - val_loss: 0.0242 - val_acc: 0.2985\n",
      "Epoch 19/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0341 - acc: 0.2340 - val_loss: 0.0288 - val_acc: 0.2388\n",
      "Epoch 20/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0305 - acc: 0.2566 - val_loss: 0.0243 - val_acc: 0.2239\n",
      "Epoch 21/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0309 - acc: 0.2642 - val_loss: 0.0323 - val_acc: 0.3284\n",
      "Epoch 22/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0319 - acc: 0.2943 - val_loss: 0.0270 - val_acc: 0.2388\n",
      "Epoch 23/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0300 - acc: 0.2377 - val_loss: 0.0247 - val_acc: 0.2985\n",
      "Epoch 24/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0322 - acc: 0.2604 - val_loss: 0.0310 - val_acc: 0.2388\n",
      "Epoch 25/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0318 - acc: 0.2377 - val_loss: 0.0247 - val_acc: 0.2985\n",
      "Epoch 26/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0319 - acc: 0.2528 - val_loss: 0.0244 - val_acc: 0.2836\n",
      "Epoch 27/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0323 - acc: 0.2679 - val_loss: 0.0421 - val_acc: 0.1791\n",
      "Epoch 28/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0347 - acc: 0.2340 - val_loss: 0.0242 - val_acc: 0.2985\n",
      "Epoch 29/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0303 - acc: 0.2642 - val_loss: 0.0288 - val_acc: 0.2687\n",
      "Epoch 30/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0312 - acc: 0.2717 - val_loss: 0.0246 - val_acc: 0.2239\n",
      "Epoch 31/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0288 - acc: 0.2528 - val_loss: 0.0268 - val_acc: 0.2239\n",
      "Epoch 32/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0293 - acc: 0.2604 - val_loss: 0.0282 - val_acc: 0.2985\n",
      "Epoch 33/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0309 - acc: 0.2943 - val_loss: 0.0255 - val_acc: 0.2985\n",
      "Epoch 34/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0311 - acc: 0.2528 - val_loss: 0.0241 - val_acc: 0.2388\n",
      "Epoch 35/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0307 - acc: 0.2302 - val_loss: 0.0319 - val_acc: 0.2388\n",
      "Epoch 36/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0289 - acc: 0.2604 - val_loss: 0.0270 - val_acc: 0.2985\n",
      "Epoch 37/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0301 - acc: 0.3094 - val_loss: 0.0259 - val_acc: 0.2985\n",
      "Epoch 38/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0287 - acc: 0.3283 - val_loss: 0.0244 - val_acc: 0.2388\n",
      "Epoch 39/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0307 - acc: 0.2038 - val_loss: 0.0295 - val_acc: 0.2985\n",
      "Epoch 40/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0298 - acc: 0.2226 - val_loss: 0.0249 - val_acc: 0.1791\n",
      "Epoch 41/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0283 - acc: 0.2226 - val_loss: 0.0260 - val_acc: 0.3134\n",
      "Epoch 42/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0289 - acc: 0.2377 - val_loss: 0.0260 - val_acc: 0.2836\n",
      "Epoch 43/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0285 - acc: 0.2453 - val_loss: 0.0285 - val_acc: 0.2985\n",
      "Epoch 44/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0297 - acc: 0.2302 - val_loss: 0.0249 - val_acc: 0.2388\n",
      "Epoch 45/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0292 - acc: 0.2264 - val_loss: 0.0258 - val_acc: 0.2985\n",
      "Epoch 46/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0282 - acc: 0.2943 - val_loss: 0.0279 - val_acc: 0.2388\n",
      "Epoch 47/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0311 - acc: 0.2340 - val_loss: 0.0333 - val_acc: 0.2836\n",
      "Epoch 48/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0298 - acc: 0.3094 - val_loss: 0.0242 - val_acc: 0.2388\n",
      "Epoch 49/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0295 - acc: 0.2642 - val_loss: 0.0279 - val_acc: 0.2985\n",
      "Epoch 50/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0282 - acc: 0.2189 - val_loss: 0.0258 - val_acc: 0.2388\n",
      "Epoch 51/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0288 - acc: 0.2151 - val_loss: 0.0252 - val_acc: 0.2985\n",
      "Epoch 52/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0288 - acc: 0.2377 - val_loss: 0.0278 - val_acc: 0.1791\n",
      "Epoch 53/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0282 - acc: 0.2642 - val_loss: 0.0286 - val_acc: 0.2090\n",
      "Epoch 54/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0288 - acc: 0.2792 - val_loss: 0.0256 - val_acc: 0.2985\n",
      "Epoch 55/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0261 - acc: 0.2679 - val_loss: 0.0266 - val_acc: 0.3433\n",
      "Epoch 56/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0267 - acc: 0.2113 - val_loss: 0.0269 - val_acc: 0.2985\n",
      "Epoch 57/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0268 - acc: 0.2717 - val_loss: 0.0251 - val_acc: 0.2687\n",
      "Epoch 58/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0306 - acc: 0.2830 - val_loss: 0.0356 - val_acc: 0.3433\n",
      "Epoch 59/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0281 - acc: 0.2264 - val_loss: 0.0245 - val_acc: 0.2687\n",
      "Epoch 60/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0286 - acc: 0.2113 - val_loss: 0.0260 - val_acc: 0.2388\n",
      "Epoch 61/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0266 - acc: 0.2415 - val_loss: 0.0303 - val_acc: 0.2239\n",
      "Epoch 62/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0274 - acc: 0.2491 - val_loss: 0.0246 - val_acc: 0.1791\n",
      "Epoch 63/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0293 - acc: 0.3057 - val_loss: 0.0350 - val_acc: 0.3284\n",
      "Epoch 64/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0306 - acc: 0.2642 - val_loss: 0.0287 - val_acc: 0.2687\n",
      "Epoch 65/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0258 - acc: 0.2566 - val_loss: 0.0255 - val_acc: 0.1791\n",
      "Epoch 66/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0268 - acc: 0.2226 - val_loss: 0.0294 - val_acc: 0.2836\n",
      "Epoch 67/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0254 - acc: 0.2792 - val_loss: 0.0285 - val_acc: 0.2537\n",
      "Epoch 68/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0262 - acc: 0.2302 - val_loss: 0.0274 - val_acc: 0.3134\n",
      "Epoch 69/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0255 - acc: 0.2642 - val_loss: 0.0294 - val_acc: 0.2388\n",
      "Epoch 70/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0238 - acc: 0.2528 - val_loss: 0.0312 - val_acc: 0.2388\n",
      "Epoch 71/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0247 - acc: 0.2377 - val_loss: 0.0294 - val_acc: 0.2836\n",
      "Epoch 72/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0252 - acc: 0.2566 - val_loss: 0.0285 - val_acc: 0.2090\n",
      "Epoch 73/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0251 - acc: 0.2642 - val_loss: 0.0355 - val_acc: 0.1791\n",
      "Epoch 74/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0262 - acc: 0.2491 - val_loss: 0.0259 - val_acc: 0.2836\n",
      "Epoch 75/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0264 - acc: 0.2264 - val_loss: 0.0271 - val_acc: 0.2836\n",
      "Epoch 76/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0257 - acc: 0.2868 - val_loss: 0.0344 - val_acc: 0.3284\n",
      "Epoch 77/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0265 - acc: 0.2943 - val_loss: 0.0258 - val_acc: 0.2388\n",
      "Epoch 78/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0264 - acc: 0.2604 - val_loss: 0.0329 - val_acc: 0.2687\n",
      "Epoch 79/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0239 - acc: 0.2642 - val_loss: 0.0284 - val_acc: 0.2836\n",
      "Epoch 80/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0249 - acc: 0.2491 - val_loss: 0.0309 - val_acc: 0.2239\n",
      "Epoch 81/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0242 - acc: 0.2453 - val_loss: 0.0281 - val_acc: 0.1940\n",
      "Epoch 82/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0226 - acc: 0.2604 - val_loss: 0.0298 - val_acc: 0.1791\n",
      "Epoch 83/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0248 - acc: 0.2868 - val_loss: 0.0310 - val_acc: 0.2836\n",
      "Epoch 84/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0236 - acc: 0.2340 - val_loss: 0.0345 - val_acc: 0.2985\n",
      "Epoch 85/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0235 - acc: 0.2377 - val_loss: 0.0267 - val_acc: 0.1940\n",
      "Epoch 86/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0231 - acc: 0.2415 - val_loss: 0.0369 - val_acc: 0.2388\n",
      "Epoch 87/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0243 - acc: 0.2906 - val_loss: 0.0321 - val_acc: 0.2836\n",
      "Epoch 88/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0244 - acc: 0.2264 - val_loss: 0.0263 - val_acc: 0.2687\n",
      "Epoch 89/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0248 - acc: 0.2717 - val_loss: 0.0396 - val_acc: 0.3284\n",
      "Epoch 90/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0234 - acc: 0.2981 - val_loss: 0.0329 - val_acc: 0.2388\n",
      "Epoch 91/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0235 - acc: 0.2453 - val_loss: 0.0275 - val_acc: 0.2388\n",
      "Epoch 92/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0236 - acc: 0.2604 - val_loss: 0.0369 - val_acc: 0.3134\n",
      "Epoch 93/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0239 - acc: 0.2415 - val_loss: 0.0298 - val_acc: 0.2687\n",
      "Epoch 94/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0231 - acc: 0.2566 - val_loss: 0.0329 - val_acc: 0.2537\n",
      "Epoch 95/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0233 - acc: 0.2566 - val_loss: 0.0348 - val_acc: 0.2537\n",
      "Epoch 96/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0234 - acc: 0.2377 - val_loss: 0.0334 - val_acc: 0.2985\n",
      "Epoch 97/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0222 - acc: 0.2528 - val_loss: 0.0318 - val_acc: 0.2836\n",
      "Epoch 98/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0215 - acc: 0.2981 - val_loss: 0.0295 - val_acc: 0.2836\n",
      "Epoch 99/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0267 - acc: 0.2868 - val_loss: 0.0385 - val_acc: 0.2985\n",
      "Epoch 100/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0225 - acc: 0.2906 - val_loss: 0.0285 - val_acc: 0.2985\n",
      "Epoch 101/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0227 - acc: 0.2642 - val_loss: 0.0305 - val_acc: 0.2388\n",
      "Epoch 102/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0231 - acc: 0.2604 - val_loss: 0.0314 - val_acc: 0.2687\n",
      "Epoch 103/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0218 - acc: 0.2340 - val_loss: 0.0311 - val_acc: 0.2687\n",
      "Epoch 104/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0228 - acc: 0.3019 - val_loss: 0.0328 - val_acc: 0.2836\n",
      "Epoch 105/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0217 - acc: 0.2377 - val_loss: 0.0315 - val_acc: 0.2687\n",
      "Epoch 106/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0210 - acc: 0.2491 - val_loss: 0.0313 - val_acc: 0.2836\n",
      "Epoch 107/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0230 - acc: 0.2377 - val_loss: 0.0332 - val_acc: 0.2687\n",
      "Epoch 108/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0221 - acc: 0.2642 - val_loss: 0.0356 - val_acc: 0.2985\n",
      "Epoch 109/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0222 - acc: 0.2377 - val_loss: 0.0335 - val_acc: 0.2388\n",
      "Epoch 110/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0203 - acc: 0.3094 - val_loss: 0.0310 - val_acc: 0.3134\n",
      "Epoch 111/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0220 - acc: 0.2717 - val_loss: 0.0312 - val_acc: 0.2836\n",
      "Epoch 112/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0213 - acc: 0.2679 - val_loss: 0.0324 - val_acc: 0.3134\n",
      "Epoch 113/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0204 - acc: 0.3019 - val_loss: 0.0427 - val_acc: 0.2836\n",
      "Epoch 114/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0247 - acc: 0.2566 - val_loss: 0.0317 - val_acc: 0.2687\n",
      "Epoch 115/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0222 - acc: 0.2491 - val_loss: 0.0360 - val_acc: 0.2687\n",
      "Epoch 116/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0213 - acc: 0.2642 - val_loss: 0.0310 - val_acc: 0.2537\n",
      "Epoch 117/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0219 - acc: 0.2264 - val_loss: 0.0296 - val_acc: 0.2537\n",
      "Epoch 118/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0203 - acc: 0.2792 - val_loss: 0.0331 - val_acc: 0.2985\n",
      "Epoch 119/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0209 - acc: 0.2453 - val_loss: 0.0327 - val_acc: 0.2537\n",
      "Epoch 120/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0215 - acc: 0.2528 - val_loss: 0.0376 - val_acc: 0.3284\n",
      "Epoch 121/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0217 - acc: 0.3057 - val_loss: 0.0370 - val_acc: 0.2985\n",
      "Epoch 122/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0212 - acc: 0.2755 - val_loss: 0.0370 - val_acc: 0.2836\n",
      "Epoch 123/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0205 - acc: 0.2642 - val_loss: 0.0305 - val_acc: 0.2687\n",
      "Epoch 124/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0204 - acc: 0.2868 - val_loss: 0.0348 - val_acc: 0.2687\n",
      "Epoch 125/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0210 - acc: 0.2302 - val_loss: 0.0370 - val_acc: 0.2836\n",
      "Epoch 126/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0205 - acc: 0.2717 - val_loss: 0.0361 - val_acc: 0.2985\n",
      "Epoch 127/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0199 - acc: 0.2981 - val_loss: 0.0320 - val_acc: 0.3134\n",
      "Epoch 128/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0207 - acc: 0.2566 - val_loss: 0.0359 - val_acc: 0.2687\n",
      "Epoch 129/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0202 - acc: 0.2264 - val_loss: 0.0371 - val_acc: 0.2985\n",
      "Epoch 130/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0210 - acc: 0.2679 - val_loss: 0.0340 - val_acc: 0.2537\n",
      "Epoch 131/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0201 - acc: 0.2717 - val_loss: 0.0385 - val_acc: 0.3134\n",
      "Epoch 132/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0208 - acc: 0.2113 - val_loss: 0.0319 - val_acc: 0.2985\n",
      "Epoch 133/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0194 - acc: 0.2642 - val_loss: 0.0348 - val_acc: 0.2836\n",
      "Epoch 134/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0205 - acc: 0.2604 - val_loss: 0.0365 - val_acc: 0.2388\n",
      "Epoch 135/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0187 - acc: 0.2679 - val_loss: 0.0337 - val_acc: 0.2687\n",
      "Epoch 136/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0197 - acc: 0.2792 - val_loss: 0.0366 - val_acc: 0.2836\n",
      "Epoch 137/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0219 - acc: 0.2566 - val_loss: 0.0341 - val_acc: 0.2687\n",
      "Epoch 138/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0237 - acc: 0.2642 - val_loss: 0.0377 - val_acc: 0.2687\n",
      "Epoch 139/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0207 - acc: 0.2491 - val_loss: 0.0297 - val_acc: 0.3284\n",
      "Epoch 140/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0209 - acc: 0.2491 - val_loss: 0.0329 - val_acc: 0.3284\n",
      "Epoch 141/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0194 - acc: 0.2377 - val_loss: 0.0360 - val_acc: 0.2687\n",
      "Epoch 142/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0203 - acc: 0.2302 - val_loss: 0.0337 - val_acc: 0.2985\n",
      "Epoch 143/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0203 - acc: 0.2906 - val_loss: 0.0377 - val_acc: 0.3134\n",
      "Epoch 144/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0204 - acc: 0.2453 - val_loss: 0.0344 - val_acc: 0.3284\n",
      "Epoch 145/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0192 - acc: 0.2943 - val_loss: 0.0356 - val_acc: 0.3134\n",
      "Epoch 146/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0197 - acc: 0.2792 - val_loss: 0.0342 - val_acc: 0.2836\n",
      "Epoch 147/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0187 - acc: 0.2830 - val_loss: 0.0376 - val_acc: 0.2985\n",
      "Epoch 148/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0199 - acc: 0.2491 - val_loss: 0.0328 - val_acc: 0.2687\n",
      "Epoch 149/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0183 - acc: 0.3019 - val_loss: 0.0392 - val_acc: 0.2836\n",
      "Epoch 150/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0186 - acc: 0.2679 - val_loss: 0.0387 - val_acc: 0.2836\n",
      "Epoch 151/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0201 - acc: 0.2868 - val_loss: 0.0363 - val_acc: 0.2985\n",
      "Epoch 152/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0186 - acc: 0.2453 - val_loss: 0.0349 - val_acc: 0.2985\n",
      "Epoch 153/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0196 - acc: 0.2453 - val_loss: 0.0361 - val_acc: 0.2985\n",
      "Epoch 154/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0199 - acc: 0.2679 - val_loss: 0.0347 - val_acc: 0.2687\n",
      "Epoch 155/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0206 - acc: 0.2679 - val_loss: 0.0336 - val_acc: 0.3433\n",
      "Epoch 156/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0193 - acc: 0.2189 - val_loss: 0.0332 - val_acc: 0.3134\n",
      "Epoch 157/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0194 - acc: 0.2679 - val_loss: 0.0359 - val_acc: 0.2836\n",
      "Epoch 158/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0187 - acc: 0.2566 - val_loss: 0.0343 - val_acc: 0.2836\n",
      "Epoch 159/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0200 - acc: 0.3245 - val_loss: 0.0400 - val_acc: 0.2687\n",
      "Epoch 160/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0185 - acc: 0.2717 - val_loss: 0.0345 - val_acc: 0.2687\n",
      "Epoch 161/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0188 - acc: 0.2528 - val_loss: 0.0355 - val_acc: 0.2687\n",
      "Epoch 162/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0192 - acc: 0.2679 - val_loss: 0.0375 - val_acc: 0.2985\n",
      "Epoch 163/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0190 - acc: 0.2566 - val_loss: 0.0354 - val_acc: 0.3284\n",
      "Epoch 164/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0192 - acc: 0.2943 - val_loss: 0.0404 - val_acc: 0.3433\n",
      "Epoch 165/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0192 - acc: 0.2642 - val_loss: 0.0341 - val_acc: 0.3284\n",
      "Epoch 166/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0178 - acc: 0.3094 - val_loss: 0.0334 - val_acc: 0.3134\n",
      "Epoch 167/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0187 - acc: 0.2642 - val_loss: 0.0368 - val_acc: 0.2537\n",
      "Epoch 168/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0189 - acc: 0.3321 - val_loss: 0.0381 - val_acc: 0.3134\n",
      "Epoch 169/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0185 - acc: 0.2792 - val_loss: 0.0402 - val_acc: 0.3433\n",
      "Epoch 170/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0184 - acc: 0.2604 - val_loss: 0.0381 - val_acc: 0.2687\n",
      "Epoch 171/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0178 - acc: 0.2642 - val_loss: 0.0398 - val_acc: 0.2836\n",
      "Epoch 172/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0190 - acc: 0.2868 - val_loss: 0.0373 - val_acc: 0.2985\n",
      "Epoch 173/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0186 - acc: 0.2717 - val_loss: 0.0419 - val_acc: 0.2985\n",
      "Epoch 174/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0188 - acc: 0.2792 - val_loss: 0.0404 - val_acc: 0.3134\n",
      "Epoch 175/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0186 - acc: 0.2642 - val_loss: 0.0421 - val_acc: 0.3134\n",
      "Epoch 176/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0190 - acc: 0.2679 - val_loss: 0.0379 - val_acc: 0.3433\n",
      "Epoch 177/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0180 - acc: 0.2830 - val_loss: 0.0368 - val_acc: 0.3284\n",
      "Epoch 178/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0175 - acc: 0.2679 - val_loss: 0.0385 - val_acc: 0.3134\n",
      "Epoch 179/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0172 - acc: 0.2906 - val_loss: 0.0429 - val_acc: 0.2687\n",
      "Epoch 180/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0172 - acc: 0.2075 - val_loss: 0.0436 - val_acc: 0.2836\n",
      "Epoch 181/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0174 - acc: 0.2868 - val_loss: 0.0372 - val_acc: 0.3433\n",
      "Epoch 182/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0171 - acc: 0.3170 - val_loss: 0.0406 - val_acc: 0.3134\n",
      "Epoch 183/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0173 - acc: 0.2453 - val_loss: 0.0415 - val_acc: 0.3284\n",
      "Epoch 184/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0184 - acc: 0.3132 - val_loss: 0.0428 - val_acc: 0.2687\n",
      "Epoch 185/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0179 - acc: 0.3019 - val_loss: 0.0334 - val_acc: 0.3134\n",
      "Epoch 186/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0177 - acc: 0.3132 - val_loss: 0.0413 - val_acc: 0.2985\n",
      "Epoch 187/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0177 - acc: 0.2792 - val_loss: 0.0410 - val_acc: 0.2836\n",
      "Epoch 188/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0181 - acc: 0.2830 - val_loss: 0.0362 - val_acc: 0.3134\n",
      "Epoch 189/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0191 - acc: 0.2755 - val_loss: 0.0344 - val_acc: 0.3433\n",
      "Epoch 190/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0186 - acc: 0.2604 - val_loss: 0.0387 - val_acc: 0.2239\n",
      "Epoch 191/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0181 - acc: 0.2717 - val_loss: 0.0352 - val_acc: 0.2836\n",
      "Epoch 192/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0173 - acc: 0.3170 - val_loss: 0.0407 - val_acc: 0.2687\n",
      "Epoch 193/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0193 - acc: 0.2755 - val_loss: 0.0387 - val_acc: 0.2985\n",
      "Epoch 194/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0173 - acc: 0.3019 - val_loss: 0.0390 - val_acc: 0.2836\n",
      "Epoch 195/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0174 - acc: 0.2566 - val_loss: 0.0313 - val_acc: 0.2836\n",
      "Epoch 196/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0173 - acc: 0.2717 - val_loss: 0.0381 - val_acc: 0.2537\n",
      "Epoch 197/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0190 - acc: 0.3019 - val_loss: 0.0371 - val_acc: 0.3284\n",
      "Epoch 198/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0178 - acc: 0.3132 - val_loss: 0.0377 - val_acc: 0.2985\n",
      "Epoch 199/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0170 - acc: 0.2792 - val_loss: 0.0385 - val_acc: 0.2239\n",
      "Epoch 200/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0171 - acc: 0.2717 - val_loss: 0.0423 - val_acc: 0.2687\n",
      "Epoch 201/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0165 - acc: 0.2906 - val_loss: 0.0374 - val_acc: 0.3582\n",
      "Epoch 202/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0171 - acc: 0.2943 - val_loss: 0.0432 - val_acc: 0.2985\n",
      "Epoch 203/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0166 - acc: 0.3094 - val_loss: 0.0419 - val_acc: 0.3134\n",
      "Epoch 204/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0163 - acc: 0.2906 - val_loss: 0.0442 - val_acc: 0.2687\n",
      "Epoch 205/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0162 - acc: 0.2717 - val_loss: 0.0445 - val_acc: 0.2537\n",
      "Epoch 206/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0166 - acc: 0.2830 - val_loss: 0.0400 - val_acc: 0.3134\n",
      "Epoch 207/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0159 - acc: 0.2943 - val_loss: 0.0459 - val_acc: 0.3284\n",
      "Epoch 208/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0162 - acc: 0.3057 - val_loss: 0.0475 - val_acc: 0.2687\n",
      "Epoch 209/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0167 - acc: 0.2642 - val_loss: 0.0431 - val_acc: 0.2836\n",
      "Epoch 210/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0156 - acc: 0.3132 - val_loss: 0.0466 - val_acc: 0.2537\n",
      "Epoch 211/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0167 - acc: 0.2943 - val_loss: 0.0426 - val_acc: 0.3134\n",
      "Epoch 212/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0157 - acc: 0.3019 - val_loss: 0.0434 - val_acc: 0.2985\n",
      "Epoch 213/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0155 - acc: 0.2717 - val_loss: 0.0396 - val_acc: 0.3284\n",
      "Epoch 214/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0164 - acc: 0.2943 - val_loss: 0.0440 - val_acc: 0.3134\n",
      "Epoch 215/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0160 - acc: 0.2906 - val_loss: 0.0396 - val_acc: 0.2836\n",
      "Epoch 216/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0169 - acc: 0.2792 - val_loss: 0.0358 - val_acc: 0.3284\n",
      "Epoch 217/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0157 - acc: 0.2604 - val_loss: 0.0457 - val_acc: 0.3134\n",
      "Epoch 218/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0155 - acc: 0.3019 - val_loss: 0.0379 - val_acc: 0.3284\n",
      "Epoch 219/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0160 - acc: 0.2755 - val_loss: 0.0427 - val_acc: 0.2687\n",
      "Epoch 220/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0177 - acc: 0.3094 - val_loss: 0.0453 - val_acc: 0.2687\n",
      "Epoch 221/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0175 - acc: 0.2679 - val_loss: 0.0372 - val_acc: 0.3134\n",
      "Epoch 222/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0161 - acc: 0.3208 - val_loss: 0.0367 - val_acc: 0.3284\n",
      "Epoch 223/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0166 - acc: 0.2830 - val_loss: 0.0505 - val_acc: 0.3433\n",
      "Epoch 224/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0150 - acc: 0.2943 - val_loss: 0.0405 - val_acc: 0.2687\n",
      "Epoch 225/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0155 - acc: 0.2528 - val_loss: 0.0418 - val_acc: 0.2687\n",
      "Epoch 226/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0156 - acc: 0.3094 - val_loss: 0.0378 - val_acc: 0.3284\n",
      "Epoch 227/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0158 - acc: 0.2755 - val_loss: 0.0415 - val_acc: 0.3284\n",
      "Epoch 228/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0154 - acc: 0.2943 - val_loss: 0.0390 - val_acc: 0.2985\n",
      "Epoch 229/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0151 - acc: 0.2868 - val_loss: 0.0398 - val_acc: 0.2836\n",
      "Epoch 230/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0157 - acc: 0.2943 - val_loss: 0.0417 - val_acc: 0.2687\n",
      "Epoch 231/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0157 - acc: 0.3094 - val_loss: 0.0453 - val_acc: 0.3134\n",
      "Epoch 232/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0156 - acc: 0.2981 - val_loss: 0.0422 - val_acc: 0.3134\n",
      "Epoch 233/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0142 - acc: 0.3019 - val_loss: 0.0425 - val_acc: 0.3134\n",
      "Epoch 234/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0154 - acc: 0.2755 - val_loss: 0.0431 - val_acc: 0.3134\n",
      "Epoch 235/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0149 - acc: 0.3434 - val_loss: 0.0427 - val_acc: 0.3134\n",
      "Epoch 236/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0141 - acc: 0.2868 - val_loss: 0.0454 - val_acc: 0.3134\n",
      "Epoch 237/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0153 - acc: 0.3170 - val_loss: 0.0368 - val_acc: 0.3134\n",
      "Epoch 238/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0151 - acc: 0.3057 - val_loss: 0.0391 - val_acc: 0.3284\n",
      "Epoch 239/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0146 - acc: 0.3208 - val_loss: 0.0415 - val_acc: 0.3134\n",
      "Epoch 240/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0144 - acc: 0.2717 - val_loss: 0.0476 - val_acc: 0.2985\n",
      "Epoch 241/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0147 - acc: 0.2642 - val_loss: 0.0417 - val_acc: 0.3284\n",
      "Epoch 242/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0157 - acc: 0.3170 - val_loss: 0.0431 - val_acc: 0.2985\n",
      "Epoch 243/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0141 - acc: 0.3094 - val_loss: 0.0432 - val_acc: 0.2537\n",
      "Epoch 244/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0143 - acc: 0.3094 - val_loss: 0.0442 - val_acc: 0.2836\n",
      "Epoch 245/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0140 - acc: 0.3132 - val_loss: 0.0441 - val_acc: 0.2985\n",
      "Epoch 246/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0142 - acc: 0.2679 - val_loss: 0.0425 - val_acc: 0.2985\n",
      "Epoch 247/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0138 - acc: 0.3208 - val_loss: 0.0451 - val_acc: 0.3284\n",
      "Epoch 248/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0143 - acc: 0.3321 - val_loss: 0.0413 - val_acc: 0.3134\n",
      "Epoch 249/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0166 - acc: 0.2906 - val_loss: 0.0396 - val_acc: 0.3134\n",
      "Epoch 250/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0162 - acc: 0.3094 - val_loss: 0.0398 - val_acc: 0.2985\n",
      "Epoch 251/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0156 - acc: 0.2830 - val_loss: 0.0415 - val_acc: 0.3134\n",
      "Epoch 252/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0150 - acc: 0.3585 - val_loss: 0.0454 - val_acc: 0.3134\n",
      "Epoch 253/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0143 - acc: 0.2943 - val_loss: 0.0406 - val_acc: 0.3433\n",
      "Epoch 254/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0141 - acc: 0.3057 - val_loss: 0.0414 - val_acc: 0.2687\n",
      "Epoch 255/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0143 - acc: 0.2679 - val_loss: 0.0454 - val_acc: 0.3134\n",
      "Epoch 256/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0132 - acc: 0.2943 - val_loss: 0.0424 - val_acc: 0.3134\n",
      "Epoch 257/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0134 - acc: 0.3509 - val_loss: 0.0455 - val_acc: 0.3134\n",
      "Epoch 258/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0135 - acc: 0.3208 - val_loss: 0.0459 - val_acc: 0.3134\n",
      "Epoch 259/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0138 - acc: 0.3019 - val_loss: 0.0402 - val_acc: 0.2985\n",
      "Epoch 260/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0138 - acc: 0.3132 - val_loss: 0.0483 - val_acc: 0.2985\n",
      "Epoch 261/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0140 - acc: 0.2868 - val_loss: 0.0464 - val_acc: 0.2836\n",
      "Epoch 262/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0134 - acc: 0.3094 - val_loss: 0.0428 - val_acc: 0.3433\n",
      "Epoch 263/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0139 - acc: 0.3585 - val_loss: 0.0431 - val_acc: 0.2687\n",
      "Epoch 264/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0140 - acc: 0.3396 - val_loss: 0.0484 - val_acc: 0.3284\n",
      "Epoch 265/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0140 - acc: 0.3019 - val_loss: 0.0429 - val_acc: 0.2836\n",
      "Epoch 266/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0134 - acc: 0.3736 - val_loss: 0.0451 - val_acc: 0.2985\n",
      "Epoch 267/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0126 - acc: 0.3132 - val_loss: 0.0431 - val_acc: 0.3134\n",
      "Epoch 268/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0132 - acc: 0.3208 - val_loss: 0.0486 - val_acc: 0.2985\n",
      "Epoch 269/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0141 - acc: 0.3132 - val_loss: 0.0466 - val_acc: 0.3134\n",
      "Epoch 270/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0133 - acc: 0.2604 - val_loss: 0.0456 - val_acc: 0.2836\n",
      "Epoch 271/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0144 - acc: 0.3283 - val_loss: 0.0398 - val_acc: 0.2985\n",
      "Epoch 272/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0134 - acc: 0.3396 - val_loss: 0.0520 - val_acc: 0.2836\n",
      "Epoch 273/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0133 - acc: 0.3509 - val_loss: 0.0452 - val_acc: 0.2687\n",
      "Epoch 274/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0135 - acc: 0.2868 - val_loss: 0.0499 - val_acc: 0.3134\n",
      "Epoch 275/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0137 - acc: 0.3396 - val_loss: 0.0423 - val_acc: 0.3134\n",
      "Epoch 276/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0132 - acc: 0.3170 - val_loss: 0.0531 - val_acc: 0.3134\n",
      "Epoch 277/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0133 - acc: 0.3849 - val_loss: 0.0510 - val_acc: 0.3433\n",
      "Epoch 278/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0134 - acc: 0.2981 - val_loss: 0.0469 - val_acc: 0.2985\n",
      "Epoch 279/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0130 - acc: 0.3434 - val_loss: 0.0511 - val_acc: 0.3433\n",
      "Epoch 280/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0126 - acc: 0.3434 - val_loss: 0.0468 - val_acc: 0.3134\n",
      "Epoch 281/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0125 - acc: 0.3358 - val_loss: 0.0488 - val_acc: 0.3284\n",
      "Epoch 282/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0128 - acc: 0.3208 - val_loss: 0.0470 - val_acc: 0.2985\n",
      "Epoch 283/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0145 - acc: 0.2868 - val_loss: 0.0379 - val_acc: 0.2687\n",
      "Epoch 284/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0148 - acc: 0.2566 - val_loss: 0.0437 - val_acc: 0.3134\n",
      "Epoch 285/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0140 - acc: 0.2906 - val_loss: 0.0418 - val_acc: 0.3134\n",
      "Epoch 286/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0139 - acc: 0.3396 - val_loss: 0.0574 - val_acc: 0.3284\n",
      "Epoch 287/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0136 - acc: 0.2981 - val_loss: 0.0472 - val_acc: 0.2836\n",
      "Epoch 288/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0136 - acc: 0.3170 - val_loss: 0.0413 - val_acc: 0.3134\n",
      "Epoch 289/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0128 - acc: 0.3472 - val_loss: 0.0526 - val_acc: 0.2985\n",
      "Epoch 290/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0127 - acc: 0.3132 - val_loss: 0.0503 - val_acc: 0.2836\n",
      "Epoch 291/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0129 - acc: 0.3358 - val_loss: 0.0457 - val_acc: 0.3134\n",
      "Epoch 292/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0126 - acc: 0.2868 - val_loss: 0.0497 - val_acc: 0.2985\n",
      "Epoch 293/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0131 - acc: 0.3132 - val_loss: 0.0457 - val_acc: 0.3284\n",
      "Epoch 294/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0127 - acc: 0.3358 - val_loss: 0.0475 - val_acc: 0.3731\n",
      "Epoch 295/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0130 - acc: 0.3170 - val_loss: 0.0485 - val_acc: 0.2985\n",
      "Epoch 296/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0127 - acc: 0.3283 - val_loss: 0.0500 - val_acc: 0.2985\n",
      "Epoch 297/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0125 - acc: 0.3245 - val_loss: 0.0434 - val_acc: 0.2985\n",
      "Epoch 298/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0129 - acc: 0.3019 - val_loss: 0.0450 - val_acc: 0.3134\n",
      "Epoch 299/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0123 - acc: 0.3283 - val_loss: 0.0490 - val_acc: 0.3433\n",
      "Epoch 300/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0124 - acc: 0.3547 - val_loss: 0.0492 - val_acc: 0.2836\n",
      "Epoch 301/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0127 - acc: 0.2981 - val_loss: 0.0484 - val_acc: 0.3134\n",
      "Epoch 302/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0127 - acc: 0.3245 - val_loss: 0.0499 - val_acc: 0.3134\n",
      "Epoch 303/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0121 - acc: 0.3434 - val_loss: 0.0512 - val_acc: 0.2836\n",
      "Epoch 304/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0130 - acc: 0.3057 - val_loss: 0.0470 - val_acc: 0.3433\n",
      "Epoch 305/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0126 - acc: 0.3283 - val_loss: 0.0542 - val_acc: 0.2836\n",
      "Epoch 306/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0133 - acc: 0.3547 - val_loss: 0.0390 - val_acc: 0.3134\n",
      "Epoch 307/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0128 - acc: 0.3094 - val_loss: 0.0435 - val_acc: 0.2985\n",
      "Epoch 308/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0129 - acc: 0.2868 - val_loss: 0.0495 - val_acc: 0.2985\n",
      "Epoch 309/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0127 - acc: 0.3019 - val_loss: 0.0512 - val_acc: 0.2537\n",
      "Epoch 310/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0124 - acc: 0.2679 - val_loss: 0.0502 - val_acc: 0.2537\n",
      "Epoch 311/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0119 - acc: 0.3358 - val_loss: 0.0533 - val_acc: 0.2687\n",
      "Epoch 312/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0125 - acc: 0.3472 - val_loss: 0.0519 - val_acc: 0.2836\n",
      "Epoch 313/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0125 - acc: 0.3321 - val_loss: 0.0513 - val_acc: 0.3134\n",
      "Epoch 314/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0128 - acc: 0.3245 - val_loss: 0.0513 - val_acc: 0.3284\n",
      "Epoch 315/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0118 - acc: 0.2868 - val_loss: 0.0455 - val_acc: 0.3134\n",
      "Epoch 316/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0125 - acc: 0.2943 - val_loss: 0.0481 - val_acc: 0.2687\n",
      "Epoch 317/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0123 - acc: 0.2755 - val_loss: 0.0519 - val_acc: 0.2836\n",
      "Epoch 318/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0126 - acc: 0.3245 - val_loss: 0.0568 - val_acc: 0.2687\n",
      "Epoch 319/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0119 - acc: 0.3509 - val_loss: 0.0571 - val_acc: 0.3134\n",
      "Epoch 320/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0116 - acc: 0.3170 - val_loss: 0.0586 - val_acc: 0.3134\n",
      "Epoch 321/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0118 - acc: 0.3623 - val_loss: 0.0506 - val_acc: 0.3582\n",
      "Epoch 322/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0118 - acc: 0.3019 - val_loss: 0.0561 - val_acc: 0.3582\n",
      "Epoch 323/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0112 - acc: 0.3358 - val_loss: 0.0479 - val_acc: 0.2687\n",
      "Epoch 324/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0113 - acc: 0.3245 - val_loss: 0.0563 - val_acc: 0.3134\n",
      "Epoch 325/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0109 - acc: 0.3623 - val_loss: 0.0450 - val_acc: 0.2836\n",
      "Epoch 326/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0118 - acc: 0.3170 - val_loss: 0.0490 - val_acc: 0.3134\n",
      "Epoch 327/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0114 - acc: 0.3283 - val_loss: 0.0512 - val_acc: 0.2836\n",
      "Epoch 328/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0113 - acc: 0.3132 - val_loss: 0.0534 - val_acc: 0.3582\n",
      "Epoch 329/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0113 - acc: 0.3321 - val_loss: 0.0531 - val_acc: 0.3284\n",
      "Epoch 330/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.0119 - acc: 0.3434 - val_loss: 0.0515 - val_acc: 0.3582\n",
      "Epoch 331/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0118 - acc: 0.3170 - val_loss: 0.0577 - val_acc: 0.3284\n",
      "Epoch 332/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0129 - acc: 0.2566 - val_loss: 0.0460 - val_acc: 0.3284\n",
      "Epoch 333/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0119 - acc: 0.3509 - val_loss: 0.0507 - val_acc: 0.3134\n",
      "Epoch 334/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0123 - acc: 0.3208 - val_loss: 0.0557 - val_acc: 0.3433\n",
      "Epoch 335/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0125 - acc: 0.3434 - val_loss: 0.0473 - val_acc: 0.2985\n",
      "Epoch 336/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0133 - acc: 0.3321 - val_loss: 0.0508 - val_acc: 0.3284\n",
      "Epoch 337/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0124 - acc: 0.3132 - val_loss: 0.0537 - val_acc: 0.2239\n",
      "Epoch 338/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0112 - acc: 0.3434 - val_loss: 0.0580 - val_acc: 0.2687\n",
      "Epoch 339/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0119 - acc: 0.2755 - val_loss: 0.0513 - val_acc: 0.2537\n",
      "Epoch 340/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0111 - acc: 0.3208 - val_loss: 0.0547 - val_acc: 0.2388\n",
      "Epoch 341/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0110 - acc: 0.3811 - val_loss: 0.0621 - val_acc: 0.2836\n",
      "Epoch 342/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0114 - acc: 0.3283 - val_loss: 0.0540 - val_acc: 0.2687\n",
      "Epoch 343/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0114 - acc: 0.3321 - val_loss: 0.0589 - val_acc: 0.3134\n",
      "Epoch 344/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0116 - acc: 0.3396 - val_loss: 0.0524 - val_acc: 0.2836\n",
      "Epoch 345/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0113 - acc: 0.3208 - val_loss: 0.0534 - val_acc: 0.2985\n",
      "Epoch 346/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0114 - acc: 0.3245 - val_loss: 0.0528 - val_acc: 0.2836\n",
      "Epoch 347/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0113 - acc: 0.3396 - val_loss: 0.0509 - val_acc: 0.3134\n",
      "Epoch 348/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0109 - acc: 0.3736 - val_loss: 0.0615 - val_acc: 0.2687\n",
      "Epoch 349/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0115 - acc: 0.3472 - val_loss: 0.0617 - val_acc: 0.2836\n",
      "Epoch 350/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0101 - acc: 0.3434 - val_loss: 0.0570 - val_acc: 0.3284\n",
      "Epoch 351/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0106 - acc: 0.3358 - val_loss: 0.0528 - val_acc: 0.3433\n",
      "Epoch 352/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0110 - acc: 0.3321 - val_loss: 0.0548 - val_acc: 0.3582\n",
      "Epoch 353/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0104 - acc: 0.3321 - val_loss: 0.0632 - val_acc: 0.3134\n",
      "Epoch 354/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0107 - acc: 0.3321 - val_loss: 0.0539 - val_acc: 0.3284\n",
      "Epoch 355/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0114 - acc: 0.3245 - val_loss: 0.0601 - val_acc: 0.3433\n",
      "Epoch 356/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0110 - acc: 0.3962 - val_loss: 0.0590 - val_acc: 0.2985\n",
      "Epoch 357/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0113 - acc: 0.3472 - val_loss: 0.0527 - val_acc: 0.3582\n",
      "Epoch 358/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0114 - acc: 0.3358 - val_loss: 0.0637 - val_acc: 0.3433\n",
      "Epoch 359/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0125 - acc: 0.3057 - val_loss: 0.0612 - val_acc: 0.3433\n",
      "Epoch 360/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0108 - acc: 0.3170 - val_loss: 0.0681 - val_acc: 0.3134\n",
      "Epoch 361/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0108 - acc: 0.3057 - val_loss: 0.0557 - val_acc: 0.3134\n",
      "Epoch 362/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0112 - acc: 0.3170 - val_loss: 0.0648 - val_acc: 0.2687\n",
      "Epoch 363/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0113 - acc: 0.3321 - val_loss: 0.0490 - val_acc: 0.3134\n",
      "Epoch 364/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0118 - acc: 0.3094 - val_loss: 0.0553 - val_acc: 0.3134\n",
      "Epoch 365/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0112 - acc: 0.3019 - val_loss: 0.0613 - val_acc: 0.3134\n",
      "Epoch 366/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0131 - acc: 0.3434 - val_loss: 0.0496 - val_acc: 0.3731\n",
      "Epoch 367/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0127 - acc: 0.3396 - val_loss: 0.0533 - val_acc: 0.3134\n",
      "Epoch 368/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0108 - acc: 0.3396 - val_loss: 0.0577 - val_acc: 0.2836\n",
      "Epoch 369/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0112 - acc: 0.3585 - val_loss: 0.0589 - val_acc: 0.2687\n",
      "Epoch 370/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0112 - acc: 0.3321 - val_loss: 0.0527 - val_acc: 0.3433\n",
      "Epoch 371/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0113 - acc: 0.3170 - val_loss: 0.0606 - val_acc: 0.2836\n",
      "Epoch 372/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0109 - acc: 0.3434 - val_loss: 0.0666 - val_acc: 0.3134\n",
      "Epoch 373/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0106 - acc: 0.3321 - val_loss: 0.0562 - val_acc: 0.3284\n",
      "Epoch 374/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0106 - acc: 0.3019 - val_loss: 0.0640 - val_acc: 0.3433\n",
      "Epoch 375/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0111 - acc: 0.3321 - val_loss: 0.0540 - val_acc: 0.3134\n",
      "Epoch 376/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0113 - acc: 0.3283 - val_loss: 0.0467 - val_acc: 0.3284\n",
      "Epoch 377/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0108 - acc: 0.3585 - val_loss: 0.0540 - val_acc: 0.3284\n",
      "Epoch 378/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0108 - acc: 0.3585 - val_loss: 0.0590 - val_acc: 0.3134\n",
      "Epoch 379/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0111 - acc: 0.3585 - val_loss: 0.0561 - val_acc: 0.3433\n",
      "Epoch 380/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.0115 - acc: 0.3623 - val_loss: 0.0581 - val_acc: 0.2687\n",
      "Epoch 381/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0110 - acc: 0.3283 - val_loss: 0.0655 - val_acc: 0.3284\n",
      "Epoch 382/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0120 - acc: 0.3547 - val_loss: 0.0499 - val_acc: 0.3284\n",
      "Epoch 383/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0109 - acc: 0.3623 - val_loss: 0.0601 - val_acc: 0.3134\n",
      "Epoch 384/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0109 - acc: 0.3132 - val_loss: 0.0529 - val_acc: 0.3134\n",
      "Epoch 385/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0109 - acc: 0.3472 - val_loss: 0.0515 - val_acc: 0.2985\n",
      "Epoch 386/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0104 - acc: 0.3057 - val_loss: 0.0610 - val_acc: 0.2836\n",
      "Epoch 387/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0104 - acc: 0.3358 - val_loss: 0.0533 - val_acc: 0.2985\n",
      "Epoch 388/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0100 - acc: 0.3358 - val_loss: 0.0606 - val_acc: 0.3284\n",
      "Epoch 389/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0102 - acc: 0.3811 - val_loss: 0.0580 - val_acc: 0.2985\n",
      "Epoch 390/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0099 - acc: 0.3434 - val_loss: 0.0648 - val_acc: 0.3134\n",
      "Epoch 391/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0115 - acc: 0.3094 - val_loss: 0.0565 - val_acc: 0.2388\n",
      "Epoch 392/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0119 - acc: 0.3170 - val_loss: 0.0628 - val_acc: 0.2985\n",
      "Epoch 393/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0122 - acc: 0.3208 - val_loss: 0.0570 - val_acc: 0.2537\n",
      "Epoch 394/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0115 - acc: 0.3358 - val_loss: 0.0632 - val_acc: 0.3134\n",
      "Epoch 395/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0106 - acc: 0.3811 - val_loss: 0.0571 - val_acc: 0.3433\n",
      "Epoch 396/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0114 - acc: 0.3358 - val_loss: 0.0602 - val_acc: 0.3284\n",
      "Epoch 397/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0107 - acc: 0.3547 - val_loss: 0.0590 - val_acc: 0.3134\n",
      "Epoch 398/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0113 - acc: 0.3509 - val_loss: 0.0712 - val_acc: 0.2985\n",
      "Epoch 399/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0111 - acc: 0.3208 - val_loss: 0.0651 - val_acc: 0.2985\n",
      "Epoch 400/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0108 - acc: 0.3585 - val_loss: 0.0621 - val_acc: 0.2687\n",
      "Epoch 401/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0126 - acc: 0.3057 - val_loss: 0.0445 - val_acc: 0.3433\n",
      "Epoch 402/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0116 - acc: 0.3396 - val_loss: 0.0590 - val_acc: 0.2836\n",
      "Epoch 403/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0105 - acc: 0.3396 - val_loss: 0.0630 - val_acc: 0.2687\n",
      "Epoch 404/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0111 - acc: 0.3472 - val_loss: 0.0597 - val_acc: 0.2687\n",
      "Epoch 405/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0101 - acc: 0.3623 - val_loss: 0.0702 - val_acc: 0.2687\n",
      "Epoch 406/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0101 - acc: 0.3698 - val_loss: 0.0593 - val_acc: 0.2836\n",
      "Epoch 407/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0097 - acc: 0.3849 - val_loss: 0.0552 - val_acc: 0.2836\n",
      "Epoch 408/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0098 - acc: 0.3434 - val_loss: 0.0618 - val_acc: 0.2985\n",
      "Epoch 409/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0100 - acc: 0.3660 - val_loss: 0.0720 - val_acc: 0.2836\n",
      "Epoch 410/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0096 - acc: 0.3094 - val_loss: 0.0654 - val_acc: 0.3134\n",
      "Epoch 411/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0096 - acc: 0.3660 - val_loss: 0.0599 - val_acc: 0.3134\n",
      "Epoch 412/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0094 - acc: 0.3698 - val_loss: 0.0643 - val_acc: 0.3284\n",
      "Epoch 413/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0098 - acc: 0.3245 - val_loss: 0.0613 - val_acc: 0.3134\n",
      "Epoch 414/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0096 - acc: 0.3509 - val_loss: 0.0670 - val_acc: 0.2687\n",
      "Epoch 415/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0099 - acc: 0.3057 - val_loss: 0.0690 - val_acc: 0.3134\n",
      "Epoch 416/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0100 - acc: 0.3358 - val_loss: 0.0576 - val_acc: 0.3284\n",
      "Epoch 417/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0101 - acc: 0.3321 - val_loss: 0.0640 - val_acc: 0.2985\n",
      "Epoch 418/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0101 - acc: 0.3396 - val_loss: 0.0615 - val_acc: 0.2985\n",
      "Epoch 419/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0100 - acc: 0.3434 - val_loss: 0.0669 - val_acc: 0.3582\n",
      "Epoch 420/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0105 - acc: 0.3774 - val_loss: 0.0592 - val_acc: 0.2687\n",
      "Epoch 421/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0101 - acc: 0.3472 - val_loss: 0.0648 - val_acc: 0.3134\n",
      "Epoch 422/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0097 - acc: 0.3698 - val_loss: 0.0612 - val_acc: 0.3134\n",
      "Epoch 423/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0106 - acc: 0.3472 - val_loss: 0.0607 - val_acc: 0.3731\n",
      "Epoch 424/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0102 - acc: 0.3396 - val_loss: 0.0594 - val_acc: 0.2985\n",
      "Epoch 425/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0103 - acc: 0.3472 - val_loss: 0.0674 - val_acc: 0.3433\n",
      "Epoch 426/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0104 - acc: 0.3434 - val_loss: 0.0606 - val_acc: 0.3582\n",
      "Epoch 427/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0102 - acc: 0.3887 - val_loss: 0.0615 - val_acc: 0.3433\n",
      "Epoch 428/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0098 - acc: 0.3623 - val_loss: 0.0641 - val_acc: 0.3284\n",
      "Epoch 429/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0096 - acc: 0.3887 - val_loss: 0.0675 - val_acc: 0.3134\n",
      "Epoch 430/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0095 - acc: 0.3396 - val_loss: 0.0559 - val_acc: 0.3433\n",
      "Epoch 431/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0096 - acc: 0.3434 - val_loss: 0.0690 - val_acc: 0.3433\n",
      "Epoch 432/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0108 - acc: 0.3509 - val_loss: 0.0612 - val_acc: 0.2985\n",
      "Epoch 433/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0105 - acc: 0.3396 - val_loss: 0.0721 - val_acc: 0.3433\n",
      "Epoch 434/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0106 - acc: 0.3623 - val_loss: 0.0556 - val_acc: 0.3284\n",
      "Epoch 435/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0101 - acc: 0.3698 - val_loss: 0.0664 - val_acc: 0.3284\n",
      "Epoch 436/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0092 - acc: 0.3849 - val_loss: 0.0661 - val_acc: 0.3433\n",
      "Epoch 437/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0100 - acc: 0.3245 - val_loss: 0.0641 - val_acc: 0.3134\n",
      "Epoch 438/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0094 - acc: 0.3736 - val_loss: 0.0722 - val_acc: 0.3284\n",
      "Epoch 439/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0104 - acc: 0.3698 - val_loss: 0.0594 - val_acc: 0.2836\n",
      "Epoch 440/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0100 - acc: 0.3623 - val_loss: 0.0641 - val_acc: 0.2985\n",
      "Epoch 441/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0097 - acc: 0.3547 - val_loss: 0.0615 - val_acc: 0.2985\n",
      "Epoch 442/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0093 - acc: 0.3774 - val_loss: 0.0594 - val_acc: 0.3134\n",
      "Epoch 443/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0095 - acc: 0.3321 - val_loss: 0.0632 - val_acc: 0.2985\n",
      "Epoch 444/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0095 - acc: 0.3660 - val_loss: 0.0631 - val_acc: 0.3433\n",
      "Epoch 445/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0094 - acc: 0.3132 - val_loss: 0.0638 - val_acc: 0.3284\n",
      "Epoch 446/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0097 - acc: 0.3358 - val_loss: 0.0609 - val_acc: 0.2537\n",
      "Epoch 447/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0098 - acc: 0.3585 - val_loss: 0.0657 - val_acc: 0.2836\n",
      "Epoch 448/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0096 - acc: 0.3660 - val_loss: 0.0636 - val_acc: 0.3134\n",
      "Epoch 449/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0094 - acc: 0.3736 - val_loss: 0.0690 - val_acc: 0.3433\n",
      "Epoch 450/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0096 - acc: 0.3509 - val_loss: 0.0598 - val_acc: 0.3134\n",
      "Epoch 451/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0098 - acc: 0.3509 - val_loss: 0.0623 - val_acc: 0.3284\n",
      "Epoch 452/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0099 - acc: 0.3547 - val_loss: 0.0639 - val_acc: 0.3284\n",
      "Epoch 453/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0106 - acc: 0.3358 - val_loss: 0.0619 - val_acc: 0.2836\n",
      "Epoch 454/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0100 - acc: 0.3509 - val_loss: 0.0638 - val_acc: 0.2687\n",
      "Epoch 455/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0099 - acc: 0.3396 - val_loss: 0.0739 - val_acc: 0.2388\n",
      "Epoch 456/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0096 - acc: 0.3509 - val_loss: 0.0609 - val_acc: 0.2537\n",
      "Epoch 457/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0090 - acc: 0.3472 - val_loss: 0.0702 - val_acc: 0.3582\n",
      "Epoch 458/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0098 - acc: 0.3509 - val_loss: 0.0605 - val_acc: 0.3134\n",
      "Epoch 459/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0099 - acc: 0.3698 - val_loss: 0.0551 - val_acc: 0.2985\n",
      "Epoch 460/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0096 - acc: 0.3547 - val_loss: 0.0596 - val_acc: 0.3134\n",
      "Epoch 461/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0094 - acc: 0.3245 - val_loss: 0.0555 - val_acc: 0.2985\n",
      "Epoch 462/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0106 - acc: 0.3094 - val_loss: 0.0555 - val_acc: 0.2687\n",
      "Epoch 463/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0094 - acc: 0.3509 - val_loss: 0.0604 - val_acc: 0.3134\n",
      "Epoch 464/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0106 - acc: 0.3396 - val_loss: 0.0639 - val_acc: 0.3881\n",
      "Epoch 465/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0113 - acc: 0.3509 - val_loss: 0.0644 - val_acc: 0.3433\n",
      "Epoch 466/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0098 - acc: 0.3811 - val_loss: 0.0644 - val_acc: 0.3731\n",
      "Epoch 467/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0094 - acc: 0.3698 - val_loss: 0.0691 - val_acc: 0.2537\n",
      "Epoch 468/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0093 - acc: 0.3660 - val_loss: 0.0678 - val_acc: 0.2836\n",
      "Epoch 469/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0091 - acc: 0.3962 - val_loss: 0.0643 - val_acc: 0.3284\n",
      "Epoch 470/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0098 - acc: 0.3245 - val_loss: 0.0667 - val_acc: 0.3134\n",
      "Epoch 471/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0097 - acc: 0.3396 - val_loss: 0.0682 - val_acc: 0.3284\n",
      "Epoch 472/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0092 - acc: 0.3321 - val_loss: 0.0749 - val_acc: 0.3582\n",
      "Epoch 473/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0103 - acc: 0.3472 - val_loss: 0.0634 - val_acc: 0.3433\n",
      "Epoch 474/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0094 - acc: 0.3547 - val_loss: 0.0633 - val_acc: 0.2537\n",
      "Epoch 475/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0100 - acc: 0.3585 - val_loss: 0.0677 - val_acc: 0.2985\n",
      "Epoch 476/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0093 - acc: 0.3774 - val_loss: 0.0721 - val_acc: 0.3433\n",
      "Epoch 477/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0094 - acc: 0.3547 - val_loss: 0.0682 - val_acc: 0.3284\n",
      "Epoch 478/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0091 - acc: 0.3623 - val_loss: 0.0674 - val_acc: 0.3134\n",
      "Epoch 479/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0096 - acc: 0.4038 - val_loss: 0.0704 - val_acc: 0.2985\n",
      "Epoch 480/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0096 - acc: 0.3585 - val_loss: 0.0644 - val_acc: 0.2836\n",
      "Epoch 481/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0090 - acc: 0.3585 - val_loss: 0.0685 - val_acc: 0.3284\n",
      "Epoch 482/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0091 - acc: 0.3358 - val_loss: 0.0651 - val_acc: 0.2985\n",
      "Epoch 483/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0096 - acc: 0.3585 - val_loss: 0.0656 - val_acc: 0.2985\n",
      "Epoch 484/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0089 - acc: 0.3698 - val_loss: 0.0699 - val_acc: 0.3284\n",
      "Epoch 485/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0095 - acc: 0.3623 - val_loss: 0.0675 - val_acc: 0.3284\n",
      "Epoch 486/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0103 - acc: 0.3245 - val_loss: 0.0563 - val_acc: 0.2985\n",
      "Epoch 487/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0101 - acc: 0.3396 - val_loss: 0.0629 - val_acc: 0.2836\n",
      "Epoch 488/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0095 - acc: 0.3623 - val_loss: 0.0566 - val_acc: 0.2836\n",
      "Epoch 489/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0091 - acc: 0.3396 - val_loss: 0.0678 - val_acc: 0.3284\n",
      "Epoch 490/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0091 - acc: 0.3736 - val_loss: 0.0626 - val_acc: 0.2985\n",
      "Epoch 491/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0088 - acc: 0.3774 - val_loss: 0.0577 - val_acc: 0.2985\n",
      "Epoch 492/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0116 - acc: 0.3660 - val_loss: 0.0599 - val_acc: 0.2985\n",
      "Epoch 493/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0097 - acc: 0.3585 - val_loss: 0.0608 - val_acc: 0.3284\n",
      "Epoch 494/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0095 - acc: 0.4075 - val_loss: 0.0630 - val_acc: 0.2985\n",
      "Epoch 495/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0086 - acc: 0.3925 - val_loss: 0.0657 - val_acc: 0.3134\n",
      "Epoch 496/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0092 - acc: 0.3472 - val_loss: 0.0599 - val_acc: 0.2985\n",
      "Epoch 497/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0084 - acc: 0.3925 - val_loss: 0.0661 - val_acc: 0.3134\n",
      "Epoch 498/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0090 - acc: 0.3660 - val_loss: 0.0628 - val_acc: 0.3582\n",
      "Epoch 499/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0094 - acc: 0.3698 - val_loss: 0.0579 - val_acc: 0.2985\n",
      "Epoch 500/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0092 - acc: 0.3245 - val_loss: 0.0643 - val_acc: 0.2985\n",
      "[0.21983957290649414, 0.06396549195051193, 0.049580514430999756, 0.04397037625312805, 0.04315413162112236, 0.03857717290520668, 0.03756687417626381, 0.03542809933423996, 0.037537578493356705, 0.036874473094940186, 0.035806749016046524, 0.03403965383768082, 0.033771973103284836, 0.031167378649115562, 0.03752366453409195, 0.03379984572529793, 0.03222016617655754, 0.03521471843123436, 0.03408771753311157, 0.030463408678770065, 0.030944963917136192, 0.031860243529081345, 0.0300256609916687, 0.032239288091659546, 0.03176378831267357, 0.03193219006061554, 0.03225884214043617, 0.03468185290694237, 0.030257876962423325, 0.031158166006207466, 0.02879224717617035, 0.029259800910949707, 0.030864611268043518, 0.03109009936451912, 0.030675698071718216, 0.02886105701327324, 0.03008326329290867, 0.028678182512521744, 0.030733181163668633, 0.029815085232257843, 0.028284547850489616, 0.028917303308844566, 0.028500795364379883, 0.029698096215724945, 0.029242534190416336, 0.028231829404830933, 0.03114979900419712, 0.029849283397197723, 0.029506143182516098, 0.028245732188224792, 0.028784509748220444, 0.028759749606251717, 0.028158782050013542, 0.028756512328982353, 0.026086363941431046, 0.026737399399280548, 0.026788072660565376, 0.030628560110926628, 0.028109407052397728, 0.02855665050446987, 0.02664113976061344, 0.027399778366088867, 0.02926015853881836, 0.030555851757526398, 0.025812625885009766, 0.02679681032896042, 0.025376860052347183, 0.026175322011113167, 0.02553854137659073, 0.023833977058529854, 0.024709360674023628, 0.025168754160404205, 0.02509850077331066, 0.026235153898596764, 0.026429904624819756, 0.02573256939649582, 0.02646050788462162, 0.02639591321349144, 0.02390057034790516, 0.024882156401872635, 0.024191202595829964, 0.02260601706802845, 0.02482323907315731, 0.023608999326825142, 0.023548301309347153, 0.023116404190659523, 0.024324335157871246, 0.0243559330701828, 0.024825984612107277, 0.023396866396069527, 0.023531325161457062, 0.023612216114997864, 0.023879000917077065, 0.023069048300385475, 0.02326282300055027, 0.023380568251013756, 0.022203104570508003, 0.021517379209399223, 0.02665148489177227, 0.022481586784124374, 0.02270771935582161, 0.02309945784509182, 0.02179376594722271, 0.022763783112168312, 0.021702606230974197, 0.020970620214939117, 0.022976351901888847, 0.0220941212028265, 0.022239195182919502, 0.020285632461309433, 0.02204698882997036, 0.02131839096546173, 0.020393548533320427, 0.02471260353922844, 0.022160250693559647, 0.021295025944709778, 0.0218944251537323, 0.020337363705039024, 0.02087245136499405, 0.021540552377700806, 0.021674765273928642, 0.021210607141256332, 0.020533587783575058, 0.020426051691174507, 0.0209644827991724, 0.020474977791309357, 0.01990627497434616, 0.020695555955171585, 0.020214583724737167, 0.0209952425211668, 0.02005048841238022, 0.020849287509918213, 0.01941477321088314, 0.020454615354537964, 0.018703946843743324, 0.019669918343424797, 0.0219237320125103, 0.02366911806166172, 0.02073828876018524, 0.020883629098534584, 0.019405342638492584, 0.020307352766394615, 0.020266294479370117, 0.020408393815159798, 0.019220763817429543, 0.019740279763936996, 0.018741361796855927, 0.019876381382346153, 0.018267733976244926, 0.01858249492943287, 0.02013089880347252, 0.018588220700621605, 0.019598258659243584, 0.019903311505913734, 0.020578162744641304, 0.01926996372640133, 0.01936713606119156, 0.0187073927372694, 0.02000780776143074, 0.018468288704752922, 0.01879691705107689, 0.019161507487297058, 0.01900615356862545, 0.019206920638680458, 0.01915360614657402, 0.017831722274422646, 0.018674982711672783, 0.01890977844595909, 0.018474601209163666, 0.0184337068349123, 0.01782592386007309, 0.0189983993768692, 0.018586119636893272, 0.018797291442751884, 0.018614161759614944, 0.01896645501255989, 0.018015000969171524, 0.017459051683545113, 0.017170388251543045, 0.01718842051923275, 0.01742892526090145, 0.01713903620839119, 0.017274148762226105, 0.01838088408112526, 0.017868023365736008, 0.017719944939017296, 0.017749223858118057, 0.018096230924129486, 0.01914813183248043, 0.018631035462021828, 0.018117055296897888, 0.01725354790687561, 0.0193060003221035, 0.017266051843762398, 0.0173733402043581, 0.01734359748661518, 0.018983595073223114, 0.017783625051379204, 0.016988880932331085, 0.01710396073758602, 0.016464585438370705, 0.017086122184991837, 0.0165818240493536, 0.016325075179338455, 0.01623346284031868, 0.016561852768063545, 0.015851106494665146, 0.016237154603004456, 0.016660494729876518, 0.015613584779202938, 0.016716482117772102, 0.01569581776857376, 0.015490174293518066, 0.016429593786597252, 0.016030339524149895, 0.01689656637609005, 0.015717366710305214, 0.015489956364035606, 0.016031766310334206, 0.017650499939918518, 0.017536710947752, 0.016092130914330482, 0.016646884381771088, 0.01498102955520153, 0.015535752288997173, 0.01564888469874859, 0.01576128415763378, 0.01536101195961237, 0.015115642920136452, 0.015695715323090553, 0.015717601403594017, 0.015602449886500835, 0.014201261103153229, 0.015394886024296284, 0.014921888709068298, 0.014146978966891766, 0.015347088687121868, 0.015122906304895878, 0.014580379240214825, 0.014395622536540031, 0.014709481969475746, 0.01574721187353134, 0.014097688719630241, 0.014271564781665802, 0.013992663472890854, 0.014238907024264336, 0.013803691603243351, 0.014253417029976845, 0.01656337082386017, 0.016247635707259178, 0.015559974126517773, 0.015005093067884445, 0.014339501038193703, 0.01408213097602129, 0.01432294026017189, 0.013192534446716309, 0.013372501358389854, 0.013456763699650764, 0.013833844102919102, 0.013837735168635845, 0.014049729332327843, 0.01337992213666439, 0.01386951096355915, 0.014009174890816212, 0.013966654427349567, 0.013391586020588875, 0.012558577582240105, 0.013174011372029781, 0.014081568457186222, 0.013254516758024693, 0.01438661478459835, 0.013424002565443516, 0.013305584900081158, 0.013519670814275742, 0.013664934784173965, 0.013216977939009666, 0.013252771459519863, 0.013390898704528809, 0.012976475991308689, 0.012564361095428467, 0.012525860220193863, 0.012777727097272873, 0.01450788602232933, 0.014777529053390026, 0.01403332594782114, 0.013916599564254284, 0.013579503633081913, 0.013583342544734478, 0.012793092988431454, 0.01271754875779152, 0.01287958212196827, 0.01264766976237297, 0.013078374788165092, 0.012667514383792877, 0.012951781041920185, 0.012688281945884228, 0.012463262304663658, 0.012857682071626186, 0.012270166538655758, 0.012375657446682453, 0.012656026519834995, 0.01273496262729168, 0.012118750251829624, 0.013009047135710716, 0.01256408728659153, 0.013258355669677258, 0.012755259871482849, 0.01294445525854826, 0.012729732319712639, 0.012387304566800594, 0.011929879896342754, 0.012533413246273994, 0.012502211146056652, 0.012815628200769424, 0.011804593726992607, 0.012508457526564598, 0.012320938520133495, 0.01258828118443489, 0.011881746351718903, 0.011642868630588055, 0.011813863180577755, 0.01180074643343687, 0.011183409951627254, 0.01134616881608963, 0.010874300263822079, 0.011776152998209, 0.011417587287724018, 0.011333085596561432, 0.011332826688885689, 0.011881927028298378, 0.011775086633861065, 0.012941365130245686, 0.011894489638507366, 0.012267534621059895, 0.012539396062493324, 0.013268036767840385, 0.012389356270432472, 0.011190511286258698, 0.011917000636458397, 0.011064243502914906, 0.010962649248540401, 0.011386388912796974, 0.011445569805800915, 0.011624076403677464, 0.011303682811558247, 0.011363220401108265, 0.011306237429380417, 0.010851454921066761, 0.011473014950752258, 0.010112612508237362, 0.010584062896668911, 0.010951664298772812, 0.010418567806482315, 0.010720862075686455, 0.011356523260474205, 0.010978038422763348, 0.011345868930220604, 0.011382725089788437, 0.012480394914746284, 0.010803502053022385, 0.010775243863463402, 0.01119035854935646, 0.011330296285450459, 0.011843507178127766, 0.011247691698372364, 0.013057400472462177, 0.012656319886446, 0.010843890719115734, 0.0112434858456254, 0.011225958354771137, 0.011319252662360668, 0.010882149450480938, 0.010583017952740192, 0.010600562207400799, 0.0111341942101717, 0.011319251731038094, 0.0108230821788311, 0.010762049816548824, 0.011111808009445667, 0.011469274759292603, 0.011037403717637062, 0.012014146894216537, 0.010899653658270836, 0.010850893333554268, 0.010903437621891499, 0.010376513004302979, 0.010428820736706257, 0.009994715452194214, 0.0101755540817976, 0.00987402442842722, 0.01154775358736515, 0.011874427087605, 0.012241855263710022, 0.011466448195278645, 0.010648776777088642, 0.011425835080444813, 0.010732105001807213, 0.011260890401899815, 0.011125773191452026, 0.01077259611338377, 0.012574073858559132, 0.011611954309046268, 0.010475020855665207, 0.011074746027588844, 0.010146313346922398, 0.010123427025973797, 0.009727542288601398, 0.009767355397343636, 0.009959300979971886, 0.009636827744543552, 0.009575486183166504, 0.009403100237250328, 0.009762912057340145, 0.009601314552128315, 0.009872323833405972, 0.010033602826297283, 0.01010275911539793, 0.010109993629157543, 0.010012524202466011, 0.010504172183573246, 0.010121314786374569, 0.009685968980193138, 0.010600474663078785, 0.010236697271466255, 0.010301615111529827, 0.01041429117321968, 0.010172768495976925, 0.009767620824277401, 0.009580469690263271, 0.009473378770053387, 0.009608649648725986, 0.010831915773451328, 0.010504089295864105, 0.010565062053501606, 0.010112096555531025, 0.00921070296317339, 0.009997732006013393, 0.009353211149573326, 0.01041367556899786, 0.00999355036765337, 0.009707906283438206, 0.009345639497041702, 0.009502546861767769, 0.009479865431785583, 0.009365924634039402, 0.00966446753591299, 0.009794325567781925, 0.009594706818461418, 0.009414070285856724, 0.009593713097274303, 0.009762756526470184, 0.009921098127961159, 0.01055095437914133, 0.009969279170036316, 0.009923703968524933, 0.00962921418249607, 0.008969582617282867, 0.009776347316801548, 0.009870696812868118, 0.00962831825017929, 0.0093619329854846, 0.010571246966719627, 0.009415281936526299, 0.01056815404444933, 0.011345095001161098, 0.009820705279707909, 0.009390450082719326, 0.009296560660004616, 0.009146655909717083, 0.009836477227509022, 0.009736958891153336, 0.009247899055480957, 0.010292897932231426, 0.009368042461574078, 0.01003258116543293, 0.009302059188485146, 0.00938495248556137, 0.009080392308533192, 0.009553606621921062, 0.009644553996622562, 0.009001207537949085, 0.0090553630143404, 0.00955356564372778, 0.008855023421347141, 0.009548329748213291, 0.010282536968588829, 0.010118790902197361, 0.009455934166908264, 0.009134278632700443, 0.009112694300711155, 0.008825051598250866, 0.011601677164435387, 0.009657899849116802, 0.00950696598738432, 0.008607793599367142, 0.009165417402982712, 0.008409622125327587, 0.008960723876953125, 0.00943860411643982, 0.009240121580660343]\n",
      "[0.22641509771347046, 0.2339622676372528, 0.2981131970882416, 0.2339622676372528, 0.23018868267536163, 0.27169811725616455, 0.3132075369358063, 0.27169811725616455, 0.2528301775455475, 0.2490566074848175, 0.26037734746932983, 0.24150943756103516, 0.3056603670120239, 0.2679245173931122, 0.23773585259914398, 0.23018868267536163, 0.29056602716445923, 0.23018868267536163, 0.2339622676372528, 0.25660377740859985, 0.2641509473323822, 0.2943396270275116, 0.23773585259914398, 0.26037734746932983, 0.23773585259914398, 0.2528301775455475, 0.2679245173931122, 0.2339622676372528, 0.2641509473323822, 0.27169811725616455, 0.2528301775455475, 0.26037734746932983, 0.2943396270275116, 0.2528301775455475, 0.23018868267536163, 0.26037734746932983, 0.3094339668750763, 0.32830187678337097, 0.2037735879421234, 0.22264151275157928, 0.22264151275157928, 0.23773585259914398, 0.24528302252292633, 0.23018868267536163, 0.22641509771347046, 0.2943396270275116, 0.2339622676372528, 0.3094339668750763, 0.2641509473323822, 0.2188679277896881, 0.21509434282779694, 0.23773585259914398, 0.2641509473323822, 0.2792452871799469, 0.2679245173931122, 0.21132075786590576, 0.27169811725616455, 0.2830188572406769, 0.22641509771347046, 0.21132075786590576, 0.24150943756103516, 0.2490566074848175, 0.3056603670120239, 0.2641509473323822, 0.25660377740859985, 0.22264151275157928, 0.2792452871799469, 0.23018868267536163, 0.2641509473323822, 0.2528301775455475, 0.23773585259914398, 0.25660377740859985, 0.2641509473323822, 0.2490566074848175, 0.22641509771347046, 0.28679245710372925, 0.2943396270275116, 0.26037734746932983, 0.2641509473323822, 0.2490566074848175, 0.24528302252292633, 0.26037734746932983, 0.28679245710372925, 0.2339622676372528, 0.23773585259914398, 0.24150943756103516, 0.29056602716445923, 0.22641509771347046, 0.27169811725616455, 0.2981131970882416, 0.24528302252292633, 0.26037734746932983, 0.24150943756103516, 0.25660377740859985, 0.25660377740859985, 0.23773585259914398, 0.2528301775455475, 0.2981131970882416, 0.28679245710372925, 0.29056602716445923, 0.2641509473323822, 0.26037734746932983, 0.2339622676372528, 0.30188679695129395, 0.23773585259914398, 0.2490566074848175, 0.23773585259914398, 0.2641509473323822, 0.23773585259914398, 0.3094339668750763, 0.27169811725616455, 0.2679245173931122, 0.30188679695129395, 0.25660377740859985, 0.2490566074848175, 0.2641509473323822, 0.22641509771347046, 0.2792452871799469, 0.24528302252292633, 0.2528301775455475, 0.3056603670120239, 0.27547168731689453, 0.2641509473323822, 0.28679245710372925, 0.23018868267536163, 0.27169811725616455, 0.2981131970882416, 0.25660377740859985, 0.22641509771347046, 0.2679245173931122, 0.27169811725616455, 0.21132075786590576, 0.2641509473323822, 0.26037734746932983, 0.2679245173931122, 0.2792452871799469, 0.25660377740859985, 0.2641509473323822, 0.2490566074848175, 0.2490566074848175, 0.23773585259914398, 0.23018868267536163, 0.29056602716445923, 0.24528302252292633, 0.2943396270275116, 0.2792452871799469, 0.2830188572406769, 0.2490566074848175, 0.30188679695129395, 0.2679245173931122, 0.28679245710372925, 0.24528302252292633, 0.24528302252292633, 0.2679245173931122, 0.2679245173931122, 0.2188679277896881, 0.2679245173931122, 0.25660377740859985, 0.324528306722641, 0.27169811725616455, 0.2528301775455475, 0.2679245173931122, 0.25660377740859985, 0.2943396270275116, 0.2641509473323822, 0.3094339668750763, 0.2641509473323822, 0.33207547664642334, 0.2792452871799469, 0.26037734746932983, 0.2641509473323822, 0.28679245710372925, 0.27169811725616455, 0.2792452871799469, 0.2641509473323822, 0.2679245173931122, 0.2830188572406769, 0.2679245173931122, 0.29056602716445923, 0.2075471729040146, 0.28679245710372925, 0.31698113679885864, 0.24528302252292633, 0.3132075369358063, 0.30188679695129395, 0.3132075369358063, 0.2792452871799469, 0.2830188572406769, 0.27547168731689453, 0.26037734746932983, 0.27169811725616455, 0.31698113679885864, 0.27547168731689453, 0.30188679695129395, 0.25660377740859985, 0.27169811725616455, 0.30188679695129395, 0.3132075369358063, 0.2792452871799469, 0.27169811725616455, 0.29056602716445923, 0.2943396270275116, 0.3094339668750763, 0.29056602716445923, 0.27169811725616455, 0.2830188572406769, 0.2943396270275116, 0.3056603670120239, 0.2641509473323822, 0.3132075369358063, 0.2943396270275116, 0.30188679695129395, 0.27169811725616455, 0.2943396270275116, 0.29056602716445923, 0.2792452871799469, 0.26037734746932983, 0.30188679695129395, 0.27547168731689453, 0.3094339668750763, 0.2679245173931122, 0.3207547068595886, 0.2830188572406769, 0.2943396270275116, 0.2528301775455475, 0.3094339668750763, 0.27547168731689453, 0.2943396270275116, 0.28679245710372925, 0.2943396270275116, 0.3094339668750763, 0.2981131970882416, 0.30188679695129395, 0.27547168731689453, 0.34339621663093567, 0.28679245710372925, 0.31698113679885864, 0.3056603670120239, 0.3207547068595886, 0.27169811725616455, 0.2641509473323822, 0.31698113679885864, 0.3094339668750763, 0.3094339668750763, 0.3132075369358063, 0.2679245173931122, 0.3207547068595886, 0.33207547664642334, 0.29056602716445923, 0.3094339668750763, 0.2830188572406769, 0.35849055647850037, 0.2943396270275116, 0.3056603670120239, 0.2679245173931122, 0.2943396270275116, 0.350943386554718, 0.3207547068595886, 0.30188679695129395, 0.3132075369358063, 0.28679245710372925, 0.3094339668750763, 0.35849055647850037, 0.3396226465702057, 0.30188679695129395, 0.37358489632606506, 0.3132075369358063, 0.3207547068595886, 0.3132075369358063, 0.26037734746932983, 0.32830187678337097, 0.3396226465702057, 0.350943386554718, 0.28679245710372925, 0.3396226465702057, 0.31698113679885864, 0.3849056661128998, 0.2981131970882416, 0.34339621663093567, 0.34339621663093567, 0.3358490467071533, 0.3207547068595886, 0.28679245710372925, 0.25660377740859985, 0.29056602716445923, 0.3396226465702057, 0.2981131970882416, 0.31698113679885864, 0.34716981649398804, 0.3132075369358063, 0.3358490467071533, 0.28679245710372925, 0.3132075369358063, 0.3358490467071533, 0.31698113679885864, 0.32830187678337097, 0.324528306722641, 0.30188679695129395, 0.32830187678337097, 0.3547169864177704, 0.2981131970882416, 0.324528306722641, 0.34339621663093567, 0.3056603670120239, 0.32830187678337097, 0.3547169864177704, 0.3094339668750763, 0.28679245710372925, 0.30188679695129395, 0.2679245173931122, 0.3358490467071533, 0.34716981649398804, 0.33207547664642334, 0.324528306722641, 0.28679245710372925, 0.2943396270275116, 0.27547168731689453, 0.324528306722641, 0.350943386554718, 0.31698113679885864, 0.36226415634155273, 0.30188679695129395, 0.3358490467071533, 0.324528306722641, 0.36226415634155273, 0.31698113679885864, 0.32830187678337097, 0.3132075369358063, 0.33207547664642334, 0.34339621663093567, 0.31698113679885864, 0.25660377740859985, 0.350943386554718, 0.3207547068595886, 0.34339621663093567, 0.33207547664642334, 0.3132075369358063, 0.34339621663093567, 0.27547168731689453, 0.3207547068595886, 0.3811320662498474, 0.32830187678337097, 0.33207547664642334, 0.3396226465702057, 0.3207547068595886, 0.324528306722641, 0.3396226465702057, 0.37358489632606506, 0.34716981649398804, 0.34339621663093567, 0.3358490467071533, 0.33207547664642334, 0.33207547664642334, 0.33207547664642334, 0.324528306722641, 0.3962264060974121, 0.34716981649398804, 0.3358490467071533, 0.3056603670120239, 0.31698113679885864, 0.3056603670120239, 0.31698113679885864, 0.33207547664642334, 0.3094339668750763, 0.30188679695129395, 0.34339621663093567, 0.3396226465702057, 0.3396226465702057, 0.35849055647850037, 0.33207547664642334, 0.31698113679885864, 0.34339621663093567, 0.33207547664642334, 0.30188679695129395, 0.33207547664642334, 0.32830187678337097, 0.35849055647850037, 0.35849055647850037, 0.35849055647850037, 0.36226415634155273, 0.32830187678337097, 0.3547169864177704, 0.36226415634155273, 0.3132075369358063, 0.34716981649398804, 0.3056603670120239, 0.3358490467071533, 0.3358490467071533, 0.3811320662498474, 0.34339621663093567, 0.3094339668750763, 0.31698113679885864, 0.3207547068595886, 0.3358490467071533, 0.3811320662498474, 0.3358490467071533, 0.3547169864177704, 0.350943386554718, 0.3207547068595886, 0.35849055647850037, 0.3056603670120239, 0.3396226465702057, 0.3396226465702057, 0.34716981649398804, 0.36226415634155273, 0.3698113262653351, 0.3849056661128998, 0.34339621663093567, 0.3660377264022827, 0.3094339668750763, 0.3660377264022827, 0.3698113262653351, 0.324528306722641, 0.350943386554718, 0.3056603670120239, 0.3358490467071533, 0.33207547664642334, 0.3396226465702057, 0.34339621663093567, 0.37735849618911743, 0.34716981649398804, 0.3698113262653351, 0.34716981649398804, 0.3396226465702057, 0.34716981649398804, 0.34339621663093567, 0.38867923617362976, 0.36226415634155273, 0.38867923617362976, 0.3396226465702057, 0.34339621663093567, 0.350943386554718, 0.3396226465702057, 0.36226415634155273, 0.3698113262653351, 0.3849056661128998, 0.324528306722641, 0.37358489632606506, 0.3698113262653351, 0.36226415634155273, 0.3547169864177704, 0.37735849618911743, 0.33207547664642334, 0.3660377264022827, 0.3132075369358063, 0.3358490467071533, 0.35849055647850037, 0.3660377264022827, 0.37358489632606506, 0.350943386554718, 0.350943386554718, 0.3547169864177704, 0.3358490467071533, 0.350943386554718, 0.3396226465702057, 0.350943386554718, 0.34716981649398804, 0.350943386554718, 0.3698113262653351, 0.3547169864177704, 0.324528306722641, 0.3094339668750763, 0.350943386554718, 0.3396226465702057, 0.350943386554718, 0.3811320662498474, 0.3698113262653351, 0.3660377264022827, 0.3962264060974121, 0.324528306722641, 0.3396226465702057, 0.33207547664642334, 0.34716981649398804, 0.3547169864177704, 0.35849055647850037, 0.37735849618911743, 0.3547169864177704, 0.36226415634155273, 0.40377357602119446, 0.35849055647850037, 0.35849055647850037, 0.3358490467071533, 0.35849055647850037, 0.3698113262653351, 0.36226415634155273, 0.324528306722641, 0.3396226465702057, 0.36226415634155273, 0.3396226465702057, 0.37358489632606506, 0.37735849618911743, 0.3660377264022827, 0.35849055647850037, 0.4075471758842468, 0.39245283603668213, 0.34716981649398804, 0.39245283603668213, 0.3660377264022827, 0.3698113262653351, 0.324528306722641]\n",
      "[0.03419605642557144, 0.03677155822515488, 0.02680959179997444, 0.02313976176083088, 0.023682851344347, 0.02459822967648506, 0.023703094571828842, 0.024226946756243706, 0.02414516732096672, 0.027868356555700302, 0.024427160620689392, 0.0255573820322752, 0.027888132259249687, 0.03376157209277153, 0.02405441179871559, 0.026466043666005135, 0.028731323778629303, 0.02422052063047886, 0.028811559081077576, 0.024297671392560005, 0.032270509749650955, 0.02700340375304222, 0.02470785193145275, 0.031033899635076523, 0.024744058027863503, 0.02444525994360447, 0.042105961591005325, 0.024178801104426384, 0.02879488281905651, 0.02462979592382908, 0.026795731857419014, 0.02815459482371807, 0.025486107915639877, 0.024054745212197304, 0.03189076855778694, 0.02695983089506626, 0.02586543932557106, 0.024372749030590057, 0.02953231893479824, 0.024857865646481514, 0.02599666453897953, 0.025985751301050186, 0.028527813032269478, 0.024915430694818497, 0.025821367278695107, 0.027900969609618187, 0.03325105085968971, 0.024247189983725548, 0.027850117534399033, 0.025792058557271957, 0.025176959112286568, 0.027792159467935562, 0.028613349422812462, 0.02557368203997612, 0.026634356006979942, 0.02688606083393097, 0.025070983916521072, 0.035588230937719345, 0.02451435849070549, 0.025971373543143272, 0.03026573732495308, 0.024611549451947212, 0.03498982638120651, 0.02867463231086731, 0.025451071560382843, 0.02944546565413475, 0.0284830741584301, 0.02744661085307598, 0.02935049869120121, 0.031157489866018295, 0.029432442039251328, 0.028468763455748558, 0.035514555871486664, 0.025879088789224625, 0.02707214094698429, 0.03437506780028343, 0.025783631950616837, 0.032937947660684586, 0.02843034453690052, 0.03093104623258114, 0.028138013556599617, 0.0298015009611845, 0.03103187493979931, 0.034473005682229996, 0.026708021759986877, 0.03688601404428482, 0.032096076756715775, 0.026333285495638847, 0.03961215913295746, 0.032944511622190475, 0.027478953823447227, 0.03687534108757973, 0.029779186472296715, 0.032905589789152145, 0.0348099023103714, 0.033376824110746384, 0.03184296563267708, 0.029542602598667145, 0.038528453558683395, 0.028498606756329536, 0.03047727793455124, 0.031442299485206604, 0.03108453005552292, 0.032803013920784, 0.03153669461607933, 0.03131968528032303, 0.033224575221538544, 0.03562482073903084, 0.033546555787324905, 0.030997764319181442, 0.031210586428642273, 0.032416947185993195, 0.042691756039857864, 0.03172547370195389, 0.03599392995238304, 0.03100970946252346, 0.029551420360803604, 0.03312523290514946, 0.03273225948214531, 0.03761406987905502, 0.03695073351264, 0.0369945764541626, 0.030458888038992882, 0.034755345433950424, 0.03700554370880127, 0.03612460941076279, 0.031964465975761414, 0.035898275673389435, 0.03714754432439804, 0.03401289880275726, 0.038537103682756424, 0.0318714901804924, 0.03477374464273453, 0.036542195826768875, 0.033738721162080765, 0.036570027470588684, 0.0340704508125782, 0.037665948271751404, 0.02970527485013008, 0.03288813680410385, 0.035996634513139725, 0.03368581831455231, 0.037710387259721756, 0.034435611218214035, 0.03564509376883507, 0.03416183963418007, 0.03760946914553642, 0.03277040272951126, 0.039186667650938034, 0.03872821480035782, 0.03625965118408203, 0.03492787852883339, 0.0360695905983448, 0.034669019281864166, 0.03364996612071991, 0.03319857642054558, 0.035853780806064606, 0.034322310239076614, 0.040032852441072464, 0.03449241444468498, 0.035465288907289505, 0.037487827241420746, 0.03540908545255661, 0.04037117585539818, 0.03414006531238556, 0.03335624560713768, 0.03678402677178383, 0.038085922598838806, 0.04024745523929596, 0.03812859207391739, 0.03977132961153984, 0.03734581172466278, 0.04187881201505661, 0.04040934145450592, 0.042118221521377563, 0.03794746473431587, 0.03682434931397438, 0.03845943138003349, 0.04292198270559311, 0.04364491626620293, 0.03723480552434921, 0.04063800349831581, 0.04151913896203041, 0.04275251552462578, 0.03344031795859337, 0.0412612184882164, 0.041014913469552994, 0.03615424409508705, 0.03442610427737236, 0.03866516798734665, 0.03520284965634346, 0.04067980498075485, 0.03866368904709816, 0.038975317031145096, 0.03134730085730553, 0.0380876362323761, 0.03712617605924606, 0.037737663835287094, 0.03846754506230354, 0.04227997735142708, 0.03738929331302643, 0.04323440417647362, 0.04193317890167236, 0.04422171413898468, 0.0444793626666069, 0.04001673310995102, 0.045890677720308304, 0.04750490561127663, 0.043126385658979416, 0.04657899960875511, 0.0426134429872036, 0.04339124634861946, 0.03957461565732956, 0.04400677978992462, 0.039589714258909225, 0.035823624581098557, 0.045734941959381104, 0.037915296852588654, 0.042685817927122116, 0.04529079794883728, 0.0372040830552578, 0.036748312413692474, 0.05045405030250549, 0.04052409902215004, 0.04178430885076523, 0.03782723471522331, 0.041475772857666016, 0.03896879404783249, 0.03975498303771019, 0.04172276705503464, 0.045272909104824066, 0.042150940746068954, 0.04252883419394493, 0.04307219386100769, 0.04271147400140762, 0.04544699564576149, 0.03677546977996826, 0.03912024199962616, 0.0414595752954483, 0.04760555550456047, 0.041657883673906326, 0.04306098446249962, 0.04319821298122406, 0.044177088886499405, 0.044094786047935486, 0.04247390106320381, 0.045117978006601334, 0.041298918426036835, 0.03958126902580261, 0.039811670780181885, 0.04146667197346687, 0.0453907810151577, 0.040552690625190735, 0.041439395397901535, 0.04539027810096741, 0.04239127039909363, 0.0455462709069252, 0.04593508318066597, 0.040207989513874054, 0.048284221440553665, 0.04643593728542328, 0.042834989726543427, 0.043059226125478745, 0.048384107649326324, 0.042871326208114624, 0.045080121606588364, 0.04309503361582756, 0.04864378273487091, 0.04659964144229889, 0.045557547360658646, 0.03977923467755318, 0.052025288343429565, 0.045161210000514984, 0.049866095185279846, 0.04232119023799896, 0.05305435508489609, 0.051031459122896194, 0.04688011854887009, 0.051135461777448654, 0.04679659754037857, 0.04883561655879021, 0.04699339345097542, 0.03785070776939392, 0.04367063194513321, 0.04181504249572754, 0.057361211627721786, 0.047225069254636765, 0.04132505878806114, 0.05260002240538597, 0.05033399909734726, 0.04565377160906792, 0.049686744809150696, 0.04569930210709572, 0.04749547690153122, 0.048474859446287155, 0.04995030164718628, 0.04338972643017769, 0.044979922473430634, 0.049025438725948334, 0.04924026504158974, 0.04840894415974617, 0.04994004964828491, 0.05119968578219414, 0.04704482853412628, 0.054200101643800735, 0.03895493596792221, 0.043509386479854584, 0.04949991777539253, 0.051211707293987274, 0.05021979659795761, 0.05332836136221886, 0.051949527114629745, 0.051329635083675385, 0.05125028267502785, 0.04553622379899025, 0.04810164123773575, 0.05190487578511238, 0.056848447769880295, 0.057090260088443756, 0.05856843292713165, 0.050633784383535385, 0.056087806820869446, 0.047934360802173615, 0.05630999431014061, 0.045015912503004074, 0.049025338143110275, 0.05120445415377617, 0.053377676755189896, 0.05307158827781677, 0.05146002769470215, 0.05766073241829872, 0.04603269696235657, 0.05071798712015152, 0.055747970938682556, 0.04725571349263191, 0.05081671103835106, 0.05374694615602493, 0.05798138305544853, 0.05126168951392174, 0.05466190725564957, 0.06209062412381172, 0.053975846618413925, 0.058885689824819565, 0.05243230238556862, 0.05340142548084259, 0.052778396755456924, 0.0508662611246109, 0.06147649511694908, 0.06173050403594971, 0.057011619210243225, 0.05276832357048988, 0.05476902425289154, 0.06321301311254501, 0.05387192964553833, 0.06013326346874237, 0.05900377035140991, 0.052743591368198395, 0.06367416679859161, 0.06119911000132561, 0.06807225942611694, 0.05566338077187538, 0.06481051445007324, 0.0489867627620697, 0.05526449903845787, 0.06130365654826164, 0.04956145957112312, 0.05332757160067558, 0.057720847427845, 0.058899521827697754, 0.052660997956991196, 0.060640860348939896, 0.06657781451940536, 0.05622924119234085, 0.06401865184307098, 0.05404771864414215, 0.046680424362421036, 0.05398520082235336, 0.05897422507405281, 0.056140750646591187, 0.05812859907746315, 0.06546864658594131, 0.04986612871289253, 0.06010551005601883, 0.05285349488258362, 0.05149642750620842, 0.060954876244068146, 0.05326090380549431, 0.0605703666806221, 0.05802709609270096, 0.06477806717157364, 0.05645443871617317, 0.06283098459243774, 0.056988682597875595, 0.06315794587135315, 0.057105135172605515, 0.060194555670022964, 0.05895818769931793, 0.07118414342403412, 0.06506086885929108, 0.06210251525044441, 0.04447769373655319, 0.05902671068906784, 0.06298534572124481, 0.05974804610013962, 0.07015757262706757, 0.05931389331817627, 0.055248163640499115, 0.061778873205184937, 0.07204950600862503, 0.06535059958696365, 0.05994994565844536, 0.06433924287557602, 0.06125772371888161, 0.06700976938009262, 0.06903757154941559, 0.05755315721035004, 0.06398149579763412, 0.061457064002752304, 0.06687889248132706, 0.05919833853840828, 0.06477800011634827, 0.061159562319517136, 0.06066364422440529, 0.05941452831029892, 0.0673978179693222, 0.060619283467531204, 0.061539750546216965, 0.06412219256162643, 0.06754342466592789, 0.05587572976946831, 0.0690004900097847, 0.061222419142723083, 0.0720907598733902, 0.0555756576359272, 0.06640493124723434, 0.06613308191299438, 0.06409565359354019, 0.07218283414840698, 0.059389013797044754, 0.06408877670764923, 0.06145888566970825, 0.05937255546450615, 0.06322614848613739, 0.06311448663473129, 0.06378234922885895, 0.06088145077228546, 0.06571705639362335, 0.0636296197772026, 0.06898322701454163, 0.05976852774620056, 0.06230902299284935, 0.06394831836223602, 0.06187804788351059, 0.06383384764194489, 0.07386621832847595, 0.06085439398884773, 0.07022643834352493, 0.06051803007721901, 0.05509696900844574, 0.0595666840672493, 0.05547609552741051, 0.055497851222753525, 0.06041835620999336, 0.06387744843959808, 0.06439957022666931, 0.06444215029478073, 0.06908928602933884, 0.06782113015651703, 0.06432686001062393, 0.06666050851345062, 0.06816407293081284, 0.07494060695171356, 0.06336585432291031, 0.06330186128616333, 0.06772039830684662, 0.07211913913488388, 0.06823311746120453, 0.06741175800561905, 0.07035163789987564, 0.0644085556268692, 0.06846790760755539, 0.06509345769882202, 0.06563261896371841, 0.06989389657974243, 0.06747250258922577, 0.0562865287065506, 0.06289497017860413, 0.05656086280941963, 0.06784211099147797, 0.06264128535985947, 0.057697586715221405, 0.059865802526474, 0.060813192278146744, 0.06304217129945755, 0.06568706780672073, 0.05992882326245308, 0.06611738353967667, 0.06279299408197403, 0.05785761773586273, 0.06429270654916763]\n",
      "[0.23880596458911896, 0.2985074520111084, 0.23880596458911896, 0.23880596458911896, 0.2985074520111084, 0.23880596458911896, 0.23880596458911896, 0.23880596458911896, 0.28358209133148193, 0.28358209133148193, 0.28358209133148193, 0.2985074520111084, 0.23880596458911896, 0.23880596458911896, 0.2985074520111084, 0.26865673065185547, 0.23880596458911896, 0.2985074520111084, 0.23880596458911896, 0.2238806039094925, 0.3283582031726837, 0.23880596458911896, 0.2985074520111084, 0.23880596458911896, 0.2985074520111084, 0.28358209133148193, 0.17910447716712952, 0.2985074520111084, 0.26865673065185547, 0.2238806039094925, 0.2238806039094925, 0.2985074520111084, 0.2985074520111084, 0.23880596458911896, 0.23880596458911896, 0.2985074520111084, 0.2985074520111084, 0.23880596458911896, 0.2985074520111084, 0.17910447716712952, 0.31343284249305725, 0.28358209133148193, 0.2985074520111084, 0.23880596458911896, 0.2985074520111084, 0.23880596458911896, 0.28358209133148193, 0.23880596458911896, 0.2985074520111084, 0.23880596458911896, 0.2985074520111084, 0.17910447716712952, 0.20895522832870483, 0.2985074520111084, 0.34328359365463257, 0.2985074520111084, 0.26865673065185547, 0.34328359365463257, 0.26865673065185547, 0.23880596458911896, 0.2238806039094925, 0.17910447716712952, 0.3283582031726837, 0.26865673065185547, 0.17910447716712952, 0.28358209133148193, 0.2537313401699066, 0.31343284249305725, 0.23880596458911896, 0.23880596458911896, 0.28358209133148193, 0.20895522832870483, 0.17910447716712952, 0.28358209133148193, 0.28358209133148193, 0.3283582031726837, 0.23880596458911896, 0.26865673065185547, 0.28358209133148193, 0.2238806039094925, 0.19402985274791718, 0.17910447716712952, 0.28358209133148193, 0.2985074520111084, 0.19402985274791718, 0.23880596458911896, 0.28358209133148193, 0.26865673065185547, 0.3283582031726837, 0.23880596458911896, 0.23880596458911896, 0.31343284249305725, 0.26865673065185547, 0.2537313401699066, 0.2537313401699066, 0.2985074520111084, 0.28358209133148193, 0.28358209133148193, 0.2985074520111084, 0.2985074520111084, 0.23880596458911896, 0.26865673065185547, 0.26865673065185547, 0.28358209133148193, 0.26865673065185547, 0.28358209133148193, 0.26865673065185547, 0.2985074520111084, 0.23880596458911896, 0.31343284249305725, 0.28358209133148193, 0.31343284249305725, 0.28358209133148193, 0.26865673065185547, 0.26865673065185547, 0.2537313401699066, 0.2537313401699066, 0.2985074520111084, 0.2537313401699066, 0.3283582031726837, 0.2985074520111084, 0.28358209133148193, 0.26865673065185547, 0.26865673065185547, 0.28358209133148193, 0.2985074520111084, 0.31343284249305725, 0.26865673065185547, 0.2985074520111084, 0.2537313401699066, 0.31343284249305725, 0.2985074520111084, 0.28358209133148193, 0.23880596458911896, 0.26865673065185547, 0.28358209133148193, 0.26865673065185547, 0.26865673065185547, 0.3283582031726837, 0.3283582031726837, 0.26865673065185547, 0.2985074520111084, 0.31343284249305725, 0.3283582031726837, 0.31343284249305725, 0.28358209133148193, 0.2985074520111084, 0.26865673065185547, 0.28358209133148193, 0.28358209133148193, 0.2985074520111084, 0.2985074520111084, 0.2985074520111084, 0.26865673065185547, 0.34328359365463257, 0.31343284249305725, 0.28358209133148193, 0.28358209133148193, 0.26865673065185547, 0.26865673065185547, 0.26865673065185547, 0.2985074520111084, 0.3283582031726837, 0.34328359365463257, 0.3283582031726837, 0.31343284249305725, 0.2537313401699066, 0.31343284249305725, 0.34328359365463257, 0.26865673065185547, 0.28358209133148193, 0.2985074520111084, 0.2985074520111084, 0.31343284249305725, 0.31343284249305725, 0.34328359365463257, 0.3283582031726837, 0.31343284249305725, 0.26865673065185547, 0.28358209133148193, 0.34328359365463257, 0.31343284249305725, 0.3283582031726837, 0.26865673065185547, 0.31343284249305725, 0.2985074520111084, 0.28358209133148193, 0.31343284249305725, 0.34328359365463257, 0.2238806039094925, 0.28358209133148193, 0.26865673065185547, 0.2985074520111084, 0.28358209133148193, 0.28358209133148193, 0.2537313401699066, 0.3283582031726837, 0.2985074520111084, 0.2238806039094925, 0.26865673065185547, 0.35820895433425903, 0.2985074520111084, 0.31343284249305725, 0.26865673065185547, 0.2537313401699066, 0.31343284249305725, 0.3283582031726837, 0.26865673065185547, 0.28358209133148193, 0.2537313401699066, 0.31343284249305725, 0.2985074520111084, 0.3283582031726837, 0.31343284249305725, 0.28358209133148193, 0.3283582031726837, 0.31343284249305725, 0.3283582031726837, 0.26865673065185547, 0.26865673065185547, 0.31343284249305725, 0.3283582031726837, 0.34328359365463257, 0.26865673065185547, 0.26865673065185547, 0.3283582031726837, 0.3283582031726837, 0.2985074520111084, 0.28358209133148193, 0.26865673065185547, 0.31343284249305725, 0.31343284249305725, 0.31343284249305725, 0.31343284249305725, 0.31343284249305725, 0.31343284249305725, 0.31343284249305725, 0.3283582031726837, 0.31343284249305725, 0.2985074520111084, 0.3283582031726837, 0.2985074520111084, 0.2537313401699066, 0.28358209133148193, 0.2985074520111084, 0.2985074520111084, 0.3283582031726837, 0.31343284249305725, 0.31343284249305725, 0.2985074520111084, 0.31343284249305725, 0.31343284249305725, 0.34328359365463257, 0.26865673065185547, 0.31343284249305725, 0.31343284249305725, 0.31343284249305725, 0.31343284249305725, 0.2985074520111084, 0.2985074520111084, 0.28358209133148193, 0.34328359365463257, 0.26865673065185547, 0.3283582031726837, 0.28358209133148193, 0.2985074520111084, 0.31343284249305725, 0.2985074520111084, 0.31343284249305725, 0.28358209133148193, 0.2985074520111084, 0.28358209133148193, 0.26865673065185547, 0.31343284249305725, 0.31343284249305725, 0.31343284249305725, 0.34328359365463257, 0.2985074520111084, 0.34328359365463257, 0.31343284249305725, 0.3283582031726837, 0.2985074520111084, 0.26865673065185547, 0.31343284249305725, 0.31343284249305725, 0.3283582031726837, 0.28358209133148193, 0.31343284249305725, 0.2985074520111084, 0.28358209133148193, 0.31343284249305725, 0.2985074520111084, 0.3283582031726837, 0.3731343150138855, 0.2985074520111084, 0.2985074520111084, 0.2985074520111084, 0.31343284249305725, 0.34328359365463257, 0.28358209133148193, 0.31343284249305725, 0.31343284249305725, 0.28358209133148193, 0.34328359365463257, 0.28358209133148193, 0.31343284249305725, 0.2985074520111084, 0.2985074520111084, 0.2537313401699066, 0.2537313401699066, 0.26865673065185547, 0.28358209133148193, 0.31343284249305725, 0.3283582031726837, 0.31343284249305725, 0.26865673065185547, 0.28358209133148193, 0.26865673065185547, 0.31343284249305725, 0.31343284249305725, 0.35820895433425903, 0.35820895433425903, 0.26865673065185547, 0.31343284249305725, 0.28358209133148193, 0.31343284249305725, 0.28358209133148193, 0.35820895433425903, 0.3283582031726837, 0.35820895433425903, 0.3283582031726837, 0.3283582031726837, 0.31343284249305725, 0.34328359365463257, 0.2985074520111084, 0.3283582031726837, 0.2238806039094925, 0.26865673065185547, 0.2537313401699066, 0.23880596458911896, 0.28358209133148193, 0.26865673065185547, 0.31343284249305725, 0.28358209133148193, 0.2985074520111084, 0.28358209133148193, 0.31343284249305725, 0.26865673065185547, 0.28358209133148193, 0.3283582031726837, 0.34328359365463257, 0.35820895433425903, 0.31343284249305725, 0.3283582031726837, 0.34328359365463257, 0.2985074520111084, 0.35820895433425903, 0.34328359365463257, 0.34328359365463257, 0.31343284249305725, 0.31343284249305725, 0.26865673065185547, 0.31343284249305725, 0.31343284249305725, 0.31343284249305725, 0.3731343150138855, 0.31343284249305725, 0.28358209133148193, 0.26865673065185547, 0.34328359365463257, 0.28358209133148193, 0.31343284249305725, 0.3283582031726837, 0.34328359365463257, 0.31343284249305725, 0.3283582031726837, 0.3283582031726837, 0.31343284249305725, 0.34328359365463257, 0.26865673065185547, 0.3283582031726837, 0.3283582031726837, 0.31343284249305725, 0.31343284249305725, 0.2985074520111084, 0.28358209133148193, 0.2985074520111084, 0.3283582031726837, 0.2985074520111084, 0.31343284249305725, 0.23880596458911896, 0.2985074520111084, 0.2537313401699066, 0.31343284249305725, 0.34328359365463257, 0.3283582031726837, 0.31343284249305725, 0.2985074520111084, 0.2985074520111084, 0.26865673065185547, 0.34328359365463257, 0.28358209133148193, 0.26865673065185547, 0.26865673065185547, 0.26865673065185547, 0.28358209133148193, 0.28358209133148193, 0.2985074520111084, 0.28358209133148193, 0.31343284249305725, 0.31343284249305725, 0.3283582031726837, 0.31343284249305725, 0.26865673065185547, 0.31343284249305725, 0.3283582031726837, 0.2985074520111084, 0.2985074520111084, 0.35820895433425903, 0.26865673065185547, 0.31343284249305725, 0.31343284249305725, 0.3731343150138855, 0.2985074520111084, 0.34328359365463257, 0.35820895433425903, 0.34328359365463257, 0.3283582031726837, 0.31343284249305725, 0.34328359365463257, 0.34328359365463257, 0.2985074520111084, 0.34328359365463257, 0.3283582031726837, 0.3283582031726837, 0.34328359365463257, 0.31343284249305725, 0.3283582031726837, 0.28358209133148193, 0.2985074520111084, 0.2985074520111084, 0.31343284249305725, 0.2985074520111084, 0.34328359365463257, 0.3283582031726837, 0.2537313401699066, 0.28358209133148193, 0.31343284249305725, 0.34328359365463257, 0.31343284249305725, 0.3283582031726837, 0.3283582031726837, 0.28358209133148193, 0.26865673065185547, 0.23880596458911896, 0.2537313401699066, 0.35820895433425903, 0.31343284249305725, 0.2985074520111084, 0.31343284249305725, 0.2985074520111084, 0.26865673065185547, 0.31343284249305725, 0.38805970549583435, 0.34328359365463257, 0.3731343150138855, 0.2537313401699066, 0.28358209133148193, 0.3283582031726837, 0.31343284249305725, 0.3283582031726837, 0.35820895433425903, 0.34328359365463257, 0.2537313401699066, 0.2985074520111084, 0.34328359365463257, 0.3283582031726837, 0.31343284249305725, 0.2985074520111084, 0.28358209133148193, 0.3283582031726837, 0.2985074520111084, 0.2985074520111084, 0.3283582031726837, 0.3283582031726837, 0.2985074520111084, 0.28358209133148193, 0.28358209133148193, 0.3283582031726837, 0.2985074520111084, 0.2985074520111084, 0.2985074520111084, 0.3283582031726837, 0.2985074520111084, 0.31343284249305725, 0.2985074520111084, 0.31343284249305725, 0.35820895433425903, 0.2985074520111084, 0.2985074520111084]\n"
     ]
    }
   ],
   "source": [
    "regressor = Sequential()\n",
    "regressor.add(Bidirectional(LSTM(units=30, return_sequences=True), input_shape = (x_train.shape[1],1) ) )\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(LSTM(units= 30 , return_sequences=True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(LSTM(units= 30 , return_sequences=True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(LSTM(units= 30))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(Dense(units = n_future,activation='linear'))\n",
    "regressor.compile(optimizer='adam', loss='mean_squared_error',metrics=['acc'])\n",
    "history = regressor.fit(x_train, y_train, epochs=500,batch_size=32,validation_split=0.20 )\n",
    "\n",
    "print(history.history['loss'])\n",
    "print(history.history['acc'])\n",
    "print(history.history['val_loss'])\n",
    "print(history.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e069be91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg_tem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>28.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>28.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>27.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>28.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>28.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>28.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>28.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>27.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>27.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>25.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>26.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>28.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>27.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>28.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>28.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>27.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>27.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>27.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Avg_tem\n",
       "0     28.45\n",
       "1     29.40\n",
       "2     29.30\n",
       "3     28.20\n",
       "4     27.60\n",
       "5     28.05\n",
       "6     27.75\n",
       "7     27.65\n",
       "8     29.10\n",
       "9     28.05\n",
       "10    28.40\n",
       "11    27.95\n",
       "12    28.25\n",
       "13    28.10\n",
       "14    28.25\n",
       "15    28.85\n",
       "16    27.70\n",
       "17    27.25\n",
       "18    25.70\n",
       "19    26.70\n",
       "20    28.35\n",
       "21    27.70\n",
       "22    28.90\n",
       "23    28.20\n",
       "24    27.75\n",
       "25    27.55\n",
       "26    27.75\n",
       "27    28.30\n",
       "28    27.75\n",
       "29    27.55"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read test dataset\n",
    "testdataset = pd.read_csv('NewSl.csv')\n",
    "#get only the temperature column\n",
    "testdataset = testdataset.iloc[0:30,6:7]\n",
    "testdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05a37ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sevindu\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "real_temperature = pd.read_csv('NewSl.csv')\n",
    "real_temperature = real_temperature.iloc[30:34,6:7]\n",
    "\n",
    "real_temperature = real_temperature.values.reshape(len(real_temperature), 1)\n",
    "testing = sc.transform(testdataset)\n",
    "testing = np.array(testing)\n",
    "testing = np.reshape(testing,(testing.shape[1],testing.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d15ec9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27.3],\n",
       "       [27.3],\n",
       "       [27.3],\n",
       "       [27. ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be0696a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "predicted_temperature = regressor.predict(testing)\n",
    "predicted_temperature = sc.inverse_transform(predicted_temperature)\n",
    "predicted_temperature = np.reshape(predicted_temperature,(predicted_temperature.shape[1],predicted_temperature.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c7b3b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27.26344 ],\n",
       "       [27.074522],\n",
       "       [27.027542],\n",
       "       [27.114056]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98ffb675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4644a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "149cb4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "RT = real_temperature\n",
    "PT = predicted_temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89decf51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03485475])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_MSE= (    (   ((PT[0]-RT[0])**2) + ((PT[1]-RT[1])**2) + ((PT[2]-RT[2])**2) + ((PT[3]-RT[3])**2)    )/4 ) \n",
    "\n",
    "model_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802fa022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
